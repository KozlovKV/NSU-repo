# Инфо
Лектор - Васкевич <3

Семинарист - Левыкин Александр Иванович

# Лекция 1
Классификация вычислительных алгоритмов:
- Матричное вычисление (вычислительные методы линала)
- Задачи оптимизации, решение нелинейных уравнений и их систем
- Интерполирование и численное дифференцирование
- Численное приближение не-полиномов
- Численное интегрирование
- Численные и разностные методы для обыкновенных диффуров

**Численный метод** - числа и арифметические действия, рапсположенные в определённом порядке

## Корень числа
Простейший численный метод - нахождение положительного квадратного корня числа $a$. Испульзуем рекуррентную формулу:

$$
x_n = \frac{1}{2}(x_{n-1} + \frac{a}{x_{n-1}})
$$

Доказывается через выведение погрешности эпсилон (с условием $\frac{x_n}{\sqrt{a}} = 1 + \epsilon_n$), которая будет убывать быстрее геометрической прогрессии с шагом $1/2$, благодаря чему $\lim_{n \rarr \infty} x_n = \sqrt{a}$

*И... Реально работает! Вот код на Питоне:*
```python
a = 2
x = 1.0
for _ in range(1000):
    x = (x + a / x) / 2.0
print(x)
```

## Общие правила численного метода
1. Исходная непрерывная задача замещается дискретной задачей (см. пример выше, где мы избавились от непрерывной функции корня)
2. Добавляется количество шагов (параметр $N$, также называется **дискретным временем**)
3. Увеличивая дискретное время, мы приблизим результат численного метода к результату непрерывного сколь угодно близко (*на третий принцип порой забивают и даже очень часто - в зависимости от решаемой задачи*)

## Floating numbers
Описывается множеством $p, t, L, U$:
- p - основание системы счисления
- t - разрядность числа
- L - нижняя граница порядка
- U - верхняя граница порядка

Нормализованные числа (точка после первого значимого числа) с плавающей точкой обозначаются как множество $F_1$, оно обладает следующими свойствами:
- Числа в нём распределены неравномерно
- В частности, чем больше модуль числа, тем больше расстояние до соседей
- Между нулём и минальным числом имеется просвет, который в $k$ раз больше следующего числа

По стандарту IEEE 754 тип данных float имеет такое распределение:
- 1 бит - знак
- 8 бит - экспонента
- 23 бита - мантисса

*На double мы тут, видимо, забили... А, нет, слегка упомянули. ну в общем, это всё мы итак знаем*

Очень часто числа округляются. Есть несколько способов:
- Вниз - $R_d(x)$ - отбрасываем избыточную для формата часть мантиссы
- Вверх - $R_u(x)$ - стандартные правила округления
- Чётное - $R_e(x)$ - отличается от округления вверх только в случае, если $x$ находится ровно между двумя ЧПТ, тогда из них берётся то число, мантисса которого заканчивается на чётное число

## Погрешности
Для вещественного числа $a$ и его приближения $a^*$

Абсолютная погрешность - положительная величина $\Delta(a^*) \ge |a^* - a|$
- Значащую цифру в приближении числа называют **верной**, если $\Delta(a^*)$ не превосходит половины единицы этого разряда (читай как $0.5 * 10^{-t}$)

Относительная погрешность: $\delta(a^*) \ge \frac{|a^* - a|}{|a^*|}$

## Неустойчивость
Вычислительный алгоритм называется **неустойчивым**, если в ходе него происходит одно из событий:
- Потеря значащих цифр
- Переполнение ЧПТ

**Обусловленность** - чувствительность задачи к начальным условиям. Если погрешность результата задачи существенно больше погрешности входных данных, то задача будет **плохо обусловленной**

# Семинар 1
## Векторные и матричные нормы
Нормы $||.||_a, ||.||_b$ эквивалентны, если
$$
\forall X : \exist C_1, C_2 : C_1||X||_b \le ||X||_a \le C_2||X||_b
$$

# Лекция 2
## Численное решение СЛАУ
Разумеется, СЛАУ можно решить, в случае невырожденной матрицы (а иначе она и не решится) методом Крамера, однако считать определитель матрицы - задача не самая лёгкая

При этом в целом на компе при $n \le 10^6$ определитель считается за разумное время, однако есть и более эффективные методы: прямой и итерационный

Однако для этих численных методов возникает погрешность. Особенно высока она будет в плохо обусловленных системах. Таким образом становится актуальным оценка обусловленности матрицы

## Оценки погрешности
### Нормы
Все нормы линейны и удовлетворяют неравенству треугольника

Стандартные нормы:
- $||\vec{u}||_{\infty} = \max_{1 \le i \le n} |u_i|$ - кубическая
- $||\vec{u}||_1 = \sum_{i=1}^n |u_i|$ - октаэдрическая
- $||\vec{u}||_2 = \sqrt{\sum_{i=1}^n |u_i|^2}$ - евклидова

Пространство $\R^n$ снабжённое одной из норм будем обозначать как $L^n$

Линейное преобразование:
$$
\vec{v} = A\vec{u}
$$

Теперь определим норму для матрицы $A$:
$$
\forall ||.|| : ||A|| = \sup_{\vec{u} \ne 0} \frac{||A\vec{u}||}{||\vec{u}||}
$$
Эта норма также удовлетворяет:
- неравенству треугольника
- однородна ($||\lambda A|| = |\lambda|||A||$)
- неравенству треугольника 2.0 ($||AB|| \le ||A||||B||$) (а также $||A\vec{u}|| \le ||A|||\vec{u}|$)

Таким образом, из стандартных норм векторов получаем такие нормы для матриц:
- $||A||_{\infty} = \max_{1 \le i \le n} \sum_{j=1}^n |a_{ij}|$ - ищем максимальную по сумме строку матрицы
- $||A||_1 = \max_{1 \le j \le n} \sum_{i=1}^n |a_{ij}|$ - почти то же, что и первое, но теперь ищем максимальную сумму по столбцам
- $||A||_2 = \sqrt{\max_{1 \le i \le n} \lambda_i(A^*A)}$
  - $\lambda_i(A^*A)$ - это с.з. матрицы $A^*A$, при этом $A^* = A^T$
  - Если $A$ симметричная, тогда $\lambda_i(A^*A) = \lambda_i(A^2) = |\lambda_i(A)|^2$

*Напоминалка:* скалярное произведение $(\vec{u}, \vec{v}) = \sum_{i=1}^n u_iv_i$

Из определения нормы матрицы следует, что если норма матрицы согласована с нормой векторов, то для единичной матрицы норма будет 1

### Обусловленность матрицы
**О.** $\mu(A) = ||A||||A^{-1}||$ называется **числом обусловленности** матрицы. Несложно заметить, что выбор нормы влияет на числа обусловленности. Также обозначается как $cond(A)$

**Т.** Если возмущение матрицы $\Delta A$ таково, что:
$$
\mu(A) \frac{||\Delta A||}{||A||} < 1
$$
Тогда возмущение вектора-решения $\Delta \vec{u}$ удовлетворяет оценке:
$$
\frac{\Delta \vec{u}}{\vec{u}} \le \frac{\mu(A)}{1 - \mu(A) \frac{||\Delta A||}{||A||}}(\frac{||\Delta \vec{f}||}{||\vec{f}||} + \frac{||\Delta A||}{||A||})
$$
*Доказывается через преобразования последней оценки при помощи $A\vec{u} = \vec{f}$ и неравенства треугольника*

**С. 1** При $\Delta A \approx 0$, получаем оценку погрешности только правой части:
$$
\frac{\Delta \vec{u}}{\vec{u}} \le \mu(A)\frac{||\Delta \vec{f}||}{||\vec{f}||}
$$

**С. 2** Если $\Delta A \Delta \vec{u} \approx 0$, то имеет место такая оценка:
$$
\frac{||\Delta \vec{u}||}{||\vec{u}||} \le \frac{||\Delta \vec{f}||}{||\vec{f}||} + \frac{||\Delta A||}{||A||}
$$

В силу неравенства треугольника 2.0 и $||AA^{-1}|| = ||E|| = 1$ получаем, что $\mu(A) \ge 1$

Если число обусловленности не превышает 10, мы говорим о слабом влиянии ошибок входных данных. При $\mu >> 100$ система плохо обусловлена

*См. пример во второй лекции на стр. 29*

**Замечание 1** - определитель матрицы может быть большим, а число обусловленности - малым (пример - диагональная матрица с $\epsilon > 0$: $\det D = \epsilon^n, \mu(D) = 1$) и наоборот (верхнетреугольная матрица с $1$ на диагонали и $-1$ над диагональную имеет $\det A = 1$, но $\mu(A) = n2^{n-1}$)

**Замечание 2** - для невырожденной матрицы $A$ и любой нормы будет иметь место оценка снизу:
$$
\mu(A) \ge \frac{|\lambda_{\max}(A)|}{|\lambda_{\min}(A)|}
$$

## Прямые методы решения СЛАУ
Для диагональной невырожденной матрицы СЛАУ распадается на $n$ простейших уравнений и решается за $n$ делений

Для диагональной матрицы идём от конца к началу, вычисляя один компонент за другим. Число операций - $O(n^2)$

Для неструктурированной матрицы сначала делаем приведение к треугольному виду, а затем как раньше. Называется алгоритм - **метод исключения Гаусса** (*реализовывали на первому курсе на императивке, так что описывать его считаю занятием не самым интересным (при этом там мы даже не только квадратные рассматривали)*)

# 24.09.11 - Семинар
*1.5 часа доказывали формулы с лекции...*

# 24.09.17 - Лекция
## Прямые методы решения СЛАУ
*Сначала повторяли совсем базу про Крамера и Гаусса*

## Метод Якоби
*Якобы Якоби был (не, ну какой каламбур-то! Ну вы поняли?! ВЫ ПОНЯЛИ?! (хочу спать...)), но... Я фронтэнд учил*

# 24.09.18 - Семинар
Когда матрица $A$

Домножение слева - перестановка строк

Домножение справа - перестановка столбцов


# 24.10.09 - Семинар
## Метод с предобуславливателем