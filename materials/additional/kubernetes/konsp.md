# 24.02.17 
Kubernetes можно описать как распределённые операционные системы.

Используется для множества задач, для которых важна параллельная работа множества задач: CI/CD, машинное обучение, бэкэнд большинства серьёзных приложений

Обеспечивает не только более эффективную работу, но и повышенную безопасность, защищая отдельные компоненты друг от друга и давая персистентность

Требования к kubernetes:
- Лёгкость добавления/удаления узлов
- Отказоустойчивость
- Балансировка загрузки
- Персистентные данные
- Мониторинг и диагностика
- Изоляция

## Устройство и терминология
Работающие в кластере машины называются нодами, которые делятся над рабочие и управляющие (мастера или control plane). На нодах даже могут стоять разные ОС и быть выбраны разные архитектуры.

Мастера могут не быть частью кластера

Компоненты kubernetes:
- Etcd - "сердце и желудок" kubernetes. Транзакционная распределённая база данных из одной таблицы. Похожа на хэш-таблицу и хранит состояние кластера на данный момент времени
  - Из распределённости следует, что Etcd есть свой кластер
- API server
  - Все операции над кластером проходят через него
  - Все запросы заключаются в создании/изменении/удалении каких-то объектов либо их просмотре
  - Предоставляют json и другие форматы для взаимодействия с компонентами и пользователями
- Kube-scheduler - занимается планированием задач (подов)
  - Опрашивает ноды на предмет доступных ресурсов, чтобы выбрать нужную
  - Следить за состоянием поды и, при необходимости, перезапускает его
- Kube-controller-manager - содержит множество контроллеров
  - node-controller
  - job controller - управляет заданиями по расписанию
  - endpoint controller - отслеживает сервисы, предоставляемые людям и связывает с ними нужные поды
  - service account & token controller - отвечает за учётные записи
    - *Отсылается на single sign model (SSM) и советует её изучить*
  - cloud-controller-manager - отвечает за общение с облачными сервисами, масштабирование (временное добавление нод определённого типа и т.п.)
  - etc.
- Компоненты для каждой ноды:
  - kublet - запускается на каждой ноде и отвечает за её связь с мастер-нодами
  - kube-proxy и CNI plugin - отвечают за связывание нодов в единую сеть
  - container-runtime

*Добавить картинку всей системы из презентации*

Утилиты для управления kubernetes:
- kubectl - классическая ctl тулза
- kube dashboard - под, живущий прямо в кластере и дающий вэб-интерфейс со статистикой

При этом API kubernetes полностью документирован, поэтому легко можно создать свои тулзы

## Технология виртуализации
Виртуализация используется ещё более широко: уже не только на серверах, но и на персональных компьютерах (*запускаем Windows на Mac и подобные приколы*)

Позволяют более эффективно использовать железо

Предшественником полноценной виртуализации стала концепция виртуальной памяти

В связи с появлением виртуальной памяти возникла необходимость запускать программы, написанные для систем с базовой адресацией. Так появились первые гипервизоры и полноценные технологии виртуализации

*Добавить скрины*

Гипервизоры делятся на 2 типа:
- Тип 1: могут работать напрямую с железом
- Тип 2: располагающиеся в ядре, перехватывающие исключения отправляемые ядром процессу гостевой ОС и симулирующие вместо них результаты корректной работы (trap & emulate)

*Дописать про критерий Попика-Голберга*

### Варианты реализации виртуализации
- Классическая (trap & emulate)
- Покомандная интерпретация (то есть пишем свою систему, начиная с ассемблера)
  - Очень медленный способ, зато через него можно сделать что угодно (в т.ч. эмулировать один процессор на другом)
- Бинарная компиляция (JIT-компиляция)
  - активно используется для прикладных программ
  - с использованием для компиляции ядер, однако, это сомнительный вариант, потому что сложно сохранить контекст прерываний
- Паравиртуализация
  - Специальная сборка ядра гостевой ОС, которая будет знать, что она гостевая. Такой вариант позволит ядру гостевой ОС сразу обращаться не к внешним устройствам и чему-то подобному, а сразу к гипервизору
- Контейнерная - *о них будет отдельно ниже*

*Тут описывал примеры прог для виртуализации и преимущества/особенности каждой из них*

Недостатки большинства методов:
- Производительность ввода-вывода (решается утсновкой гостевых драйверов)
- Производительность операцией по работе с виртуальной памятью
- Промывание кэша, конкуренция за системную шину
- Таймеры TCP/IP - без дополнительных ухищрений рискуем устанавливать соединение с большой задержкой либо не устанавливать его вовсе

### Контейнерная виртуализация
- Остаётся одно ядро (нет никакого гостевого)
- Каждый процесс работает в своём пространстве имён (namespace) и не имеет доступа к другим нэймспэйсам. Для каждого процесса есть несколько нэймспэйсов:
  - PID namespace - тут всё ясно
  - mount namespace - пространство имён монтирования ФС
  - web namespace - определяет, как контейнер с этим пространством имён будет маршрутизироваться

За счёт того, что ядро остаётся одно, мы избегаем большинства проблем, описанных выше

Docker - не вдаваясь в детали и особенности других прог для контейнерной виртуализации, отмечу, что особенность контейнеров докера в том, что они предназначены для запуска в контейнрах отдельных приложений

# 24.02.24
## Немного практики
1. Ставить надо `docker.io`, а не просто `docker`!
2. После установки надо добавить себя в группу `docker`

`docker run [args] <image-name>` - запустить образ
- Если докер не найдёт образ для запуска локально, то он будет искать его на докер хабе. При этом после использования образы автоматически не удаляются
- `--rm` - удалить контейнер после отработки
- `--restart [no | on-failure[:max-retries] | always | unless-stopped]` - перезапускает контейнер. Подробное описание смотри [тут](https://docs.docker.com/config/containers/start-containers-automatically/#use-a-restart-policy)
- `-d` - запустить как демона. По идее, при запуске в режиме д
- `-v /path/on/host:/path/in/container` - связать папку хоста с внутренней папкой
- `-p <host_port>:<container_port>` - пробросить порт от хоста к контейнеру
- `--name <container_name>` - задать имя контейнеру. По умолчанию будет сгенерировано нечто, похожее на человеческое имя

`docker ps` - показать список работающих контейнеров

`docker stop <container_name>` - остановить контейнер

`docker rm <container_name>` - удалить контейнер (может быть задано автоматически)

`docker inspect <container_name>` - выводит в STDOUT json с параметрами контейнера
- Пока что мы оттуда брали только его локальный IP
- Удобно перенаправить вывод в утилиту `jq`
  - После `jq` можно указывать фильтры в таком формате: `jq '.[index].name'` - и так можно комбинировать длинные запросы
  - Такой запрос выведет IP контейнера: `docker inspect my_nginx_http | jq '.[0].NetworkSettings.IPAddress'`

`docker images` - показать локальные образы

`docker image prune` - удалить все образы
- `-a` удалить образы, с которыми ничто не ассоциировано

`docker exec <container_name> <cmd>` - исполнить команду внутри контейнера
- `-i` - исполнить в интерактивном режиме (привязать STDIN/STDOUT)
- `-t` - создать терминальную сессию
- `-w /path/to/working/dir` - задать рабочий каталог
- Для "входа" в контейнер можно исполнить `docker exec -it <container_name> /bin/bash` (при условии, что у нас есть в контейнере `/bin/bash`, что бывает далеко не всегда)

Процессы, работающие в контейнере (`ls /proc`), будут отображаться и в обычной системе (`ps -aef | grep docker`), но PIDы у них будут разные. При этом будет выбран и свой процесс "init" (PID = 1), однако в общем случае он не будет выполнять все обязанности инита. В частности, не будет избавляться от зомби. Поэтому при создании образа необходимо это учитывать и вызывать `wait` в том процессе, который будет инитом контейнера либо, что рекомендуется самими разработчиками, запускать в контейнере лишь один процесс либо их небольшое фиксированное количество

На самом деле докер-образ состоит из слоёв, которые представляют собой архивы. При этом в разных образах могут комбинироваться эти слои. Если в нескольких образах используется один и тот же слой, он будет храниться в памяти всего один раз. Эти изначальные слои не изменяются, поверх них накладываются слои изменений в рамках конкретного контейнера
- `mount` без аргументов позволяет просмотреть все смонтированные ФС