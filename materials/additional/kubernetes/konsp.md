# 24.02.17 
Kubernetes можно описать как распределённые операционные системы.

Используется для множества задач, для которых важна параллельная работа множества задач: CI/CD, машинное обучение, бэкэнд большинства серьёзных приложений

Обеспечивает не только более эффективную работу, но и повышенную безопасность, защищая отдельные компоненты друг от друга и давая персистентность

Требования к kubernetes:
- Лёгкость добавления/удаления узлов
- Отказоустойчивость
- Балансировка загрузки
- Персистентные данные
- Мониторинг и диагностика
- Изоляция

## Устройство и терминология
Работающие в кластере машины называются нодами, которые делятся над рабочие и управляющие (мастера или control plane). На нодах даже могут стоять разные ОС и быть выбраны разные архитектуры.

Мастера могут не быть частью кластера

Компоненты kubernetes:
- Etcd - "сердце и желудок" kubernetes. Транзакционная распределённая база данных из одной таблицы. Похожа на хэш-таблицу и хранит состояние кластера на данный момент времени
  - Из распределённости следует, что Etcd есть свой кластер
- API server
  - Все операции над кластером проходят через него
  - Все запросы заключаются в создании/изменении/удалении каких-то объектов либо их просмотре
  - Предоставляют json и другие форматы для взаимодействия с компонентами и пользователями
- Kube-scheduler - занимается планированием задач (подов)
  - Опрашивает ноды на предмет доступных ресурсов, чтобы выбрать нужную
  - Следить за состоянием поды и, при необходимости, перезапускает его
- Kube-controller-manager - содержит множество контроллеров
  - node-controller
  - job controller - управляет заданиями по расписанию
  - endpoint controller - отслеживает сервисы, предоставляемые людям и связывает с ними нужные поды
  - service account & token controller - отвечает за учётные записи
    - *Отсылается на single sign model (SSM) и советует её изучить*
  - cloud-controller-manager - отвечает за общение с облачными сервисами, масштабирование (временное добавление нод определённого типа и т.п.)
  - etc.
- Компоненты для каждой ноды:
  - kubelet - запускается на каждой ноде и отвечает за её связь с мастер-нодами
  - kube-proxy и CNI plugin - отвечают за связывание нодов в единую сеть
  - container-runtime

*Добавить картинку всей системы из презентации*

Утилиты для управления kubernetes:
- kubectl - классическая ctl тулза
- kube dashboard - под, живущий прямо в кластере и дающий вэб-интерфейс со статистикой

При этом API kubernetes полностью документирован, поэтому легко можно создать свои тулзы

## Технология виртуализации
Виртуализация используется ещё более широко: уже не только на серверах, но и на персональных компьютерах (*запускаем Windows на Mac и подобные приколы*)

Позволяют более эффективно использовать железо

Предшественником полноценной виртуализации стала концепция виртуальной памяти

В связи с появлением виртуальной памяти возникла необходимость запускать программы, написанные для систем с базовой адресацией. Так появились первые гипервизоры и полноценные технологии виртуализации

*Добавить скрины*

Гипервизоры делятся на 2 типа:
- Тип 1: могут работать напрямую с железом
- Тип 2: располагающиеся в ядре, перехватывающие исключения отправляемые ядром процессу гостевой ОС и симулирующие вместо них результаты корректной работы (trap & emulate)

*Дописать про критерий Попика-Голберга*

### Варианты реализации виртуализации
- Классическая (trap & emulate)
- Покомандная интерпретация (то есть пишем свою систему, начиная с ассемблера)
  - Очень медленный способ, зато через него можно сделать что угодно (в т.ч. эмулировать один процессор на другом)
- Бинарная компиляция (JIT-компиляция)
  - активно используется для прикладных программ
  - с использованием для компиляции ядер, однако, это сомнительный вариант, потому что сложно сохранить контекст прерываний
- Паравиртуализация
  - Специальная сборка ядра гостевой ОС, которая будет знать, что она гостевая. Такой вариант позволит ядру гостевой ОС сразу обращаться не к внешним устройствам и чему-то подобному, а сразу к гипервизору
- Контейнерная - *о них будет отдельно ниже*

*Тут описывал примеры прог для виртуализации и преимущества/особенности каждой из них*

Недостатки большинства методов:
- Производительность ввода-вывода (решается утсновкой гостевых драйверов)
- Производительность операцией по работе с виртуальной памятью
- Промывание кэша, конкуренция за системную шину
- Таймеры TCP/IP - без дополнительных ухищрений рискуем устанавливать соединение с большой задержкой либо не устанавливать его вовсе

### Контейнерная виртуализация
- Остаётся одно ядро (нет никакого гостевого)
- Каждый процесс работает в своём пространстве имён (namespace) и не имеет доступа к другим нэймспэйсам. Для каждого процесса есть несколько нэймспэйсов:
  - PID namespace - тут всё ясно
  - mount namespace - пространство имён монтирования ФС
  - web namespace - определяет, как контейнер с этим пространством имён будет маршрутизироваться

За счёт того, что ядро остаётся одно, мы избегаем большинства проблем, описанных выше

Docker - не вдаваясь в детали и особенности других прог для контейнерной виртуализации, отмечу, что особенность контейнеров докера в том, что они предназначены для запуска в контейнрах отдельных приложений

# 24.02.24
## Немного практики
1. Ставить надо `docker.io`, а не просто `docker`!
2. После установки надо добавить себя в группу `docker`

`docker run [args] <image-name>` - запустить образ
- Если докер не найдёт образ для запуска локально, то он будет искать его на докер хабе. При этом после использования образы автоматически не удаляются
- `--rm` - удалить контейнер после отработки
- `--restart [no | on-failure[:max-retries] | always | unless-stopped]` - перезапускает контейнер. Подробное описание смотри [тут](https://docs.docker.com/config/containers/start-containers-automatically/#use-a-restart-policy)
- `-d` - запустить как демона
- `-v /path/on/host:/path/in/container` - связать папку хоста с внутренней папкой
- `-p <host_port>:<container_port>` - пробросить порт от хоста к контейнеру
- `--name <container_name>` - задать имя контейнеру. По умолчанию будет сгенерировано нечто, похожее на человеческое имя

`docker ps` - показать список работающих контейнеров

`docker stop <container_name>` - остановить контейнер

`docker rm <container_name>` - удалить контейнер (может быть задано автоматически)

`docker inspect <container_name>` - выводит в STDOUT json с параметрами контейнера
- Пока что мы оттуда брали только его локальный IP
- Удобно перенаправить вывод в утилиту `jq`
  - После `jq` можно указывать фильтры в таком формате: `jq '.[index].name'` - и так можно комбинировать длинные запросы
  - Такой запрос выведет IP контейнера: `docker inspect my_nginx_http | jq '.[0].NetworkSettings.IPAddress'`

`docker images` - показать локальные образы

`docker image prune` - удалить все образы
- `-a` удалить образы, с которыми ничто не ассоциировано

`docker exec <container_name> <cmd>` - исполнить команду внутри контейнера
- `-i` - исполнить в интерактивном режиме (привязать STDIN/STDOUT)
- `-t` - создать терминальную сессию
- `-w /path/to/working/dir` - задать рабочий каталог
- Для "входа" в контейнер можно исполнить `docker exec -it <container_name> /bin/bash` (при условии, что у нас есть в контейнере `/bin/bash`, что бывает далеко не всегда)

Процессы, работающие в контейнере (`ls /proc`), будут отображаться и в обычной системе (`ps -aef | grep docker`), но PIDы у них будут разные. При этом будет выбран и свой процесс "init" (PID = 1), однако в общем случае он не будет выполнять все обязанности инита. В частности, не будет избавляться от зомби. Поэтому при создании образа необходимо это учитывать и вызывать `wait` в том процессе, который будет инитом контейнера либо, что рекомендуется самими разработчиками, запускать в контейнере лишь один процесс либо их небольшое фиксированное количество

На самом деле докер-образ состоит из слоёв, которые представляют собой архивы. При этом в разных образах могут комбинироваться эти слои. Если в нескольких образах используется один и тот же слой, он будет храниться в памяти всего один раз. Эти изначальные слои не изменяются, поверх них накладываются слои изменений в рамках конкретного контейнера
- `mount` без аргументов позволяет просмотреть все смонтированные ФС

# 24.03.02
## Управление пакетами
За установку пакетов отвечают 2 утилиты: `dpkg` и `apt`

`dpkg`:
- Устанвливает отдельные пакеты и может вывести о них инфу и список зависимостей (в том числе заявить, что его)
- Показывает список установленных пакетов
- Может собирать пакеты из исходников
- НЕ МОЖЕТ устанавливать зависимости

`apt`:
- Может работать с пакетными репозиториями
- Рекурсивно устанавливает зависимости
- Может обновлять систему

`deb`-пакет - файл пакета, который, в некотором смысле, похож на архив и содержит:
- `control.tar.gz`
- `data.tar.gz`
- `debian-binary`

### `dpkg`
- `-i <file.deb>` - установить пакет
- `-R <dir>` - установить все пакеты в директории
- `-r <package>` - удалить пакет
- `-P <package>` - удалить пакет и конфиги
- `-l` - показать список пакетов
- `-S <file>` - показать, какой пакет работает с этим файлом
- `-p <package>` - показать информацию о пакете

### `apt`
Включает в себя суб-команды от команд `apt-get`, `apt-show`, `apt-cache`

Команды от `apt-cache`:
- `search <term>`
- `pkgnames <term>`
- `showkpg <package>` - информация о пакете (установленном?)

`apt-get` (частично):
- `update`
- `upgrade`
- `dist-upgrade` - не следить за работоспособностью системы на каждом этапе. Нужен для радикального перехода на новую версию системы (с одной Stable version на другую)
- `autoremove` - удалить пакеты, которые ставились как зависимости, но больше не используются (почистить мусор)
- `install <package1> [<package2>, ...]`
  - `--no-upgrade` - не обновлять уже имеющиеся пакеты, только поставить новые
  - `--only-upgrade` - только обновлять пакеты
  - `<package>=<version>` - так тоже можно
  - можно также указать `deb`-пакет

`apt-mark <mark> <package>` - поставить особые метки на пакеты. Полных их перечень смотри в `man apt-mark`


# 24.03.09 - лекция
## `systemd`
Инитов за всю историю было много

Одним из устаревши, но популярных, был инит SystemV. Его сотатки можно наблюдать в `/etc/init.d` - на файлы из этих папок идут симлинки из папок `/etc/rc<NUM>.d/`, в которых `<NUM>` находится в диапазоне от 0 до 6. Каждый из вариантов `rc` определяет свой режим работы системы (один пользователь / много пользователей, без сети / с сетью, с GUI / без GUI). У симлинков в начале идёт буква `S` либо `K`. Если там буква `S`, значит нужно запустить сервис с командой `start`, иначе - с командой `stop`

Содержание `ini`-файла сервиса:
```ini
[Unit] # Информация о сервисе
Description=
After=<service> # После кого стартовать
Wants=<dependencies> # Какие сервисы нужны для работы

[Service] # Собственно, основная работа сервиса
Type=<type> # Определяет тип сервиса (пока что видел только notify)
ExecStart=<command_with_full_path_to_binary>
ExecReload=<command_with_full_path_to_binary>
TimeoutSec=<seconds>
RestartSec=<seconds>
Restart=always # ну и другие варианты, само собой, возможны

[Install]
wantedBy=<target> # пишем, какие группы сервисов зависят от этого сервиса
```

Старой командой для работы с сервисами была `service`, теперь чаще используются `systemctl`

`systemctl` - выведет все сервисы

`systemctl <cmd> <serviceName>`. `<cmd>`:
- `enable` - запускать сервис при старте
- `disable` - отменить автоматический запуск при старте системы
- `status` 

`journalctl` - вывод всего лога системы
- `journalctl -u <serviceName>` - вывод лога сервиса

## Сборка docker-образов
Сборка происходит при помощи файла `dockerfile`:
```dockerfile
FROM nginx:latest

...

COPY

...

# Определяем, какой сигнал будет послан init-процессу контейнера при вызове нами docker stop. При этом сигнал получит только сам init. Как убить остальные процессы - забота инита (а также его забота - убивать зомби)
STOPSIGNAL SIGQUIT 
```

Ещё немного докерных команд:
- `docker build <path/to/dockerfile>` - собрать образ
- `docker tag <imageID> <tag>` - установить тэг образа

## Наконец, сам kubernetes
[Инструкция по установке](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)