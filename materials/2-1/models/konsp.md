- [Инфо](#инфо)
- [23.09.05 - лекция](#230905---лекция)
- [23.09.12 - лекция](#230912---лекция)
  - [Автоматы (*вроде бы недетерминированные, но понимаю, что к чему, слабо*)](#автоматы-вроде-бы-недетерминированные-но-понимаю-что-к-чему-слабо)
- [23.09.12 - семинар](#230912---семинар)
  - [Детерминированные конечные автоматы (ДКА)](#детерминированные-конечные-автоматы-дка)
- [23.09.19 - лекция](#230919---лекция)
- [23.09.19 - семинар](#230919---семинар)
- [23.09.26 - лекция](#230926---лекция)
- [23.09.26 - семинар](#230926---семинар)
  - [Детерминизация НКА](#детерминизация-нка)
- [23.10.03 - лекция](#231003---лекция)
- [23.10.03 - семинар](#231003---семинар)
- [Подготовка к КР](#подготовка-к-кр)
- [23.10.10 - лекция](#231010---лекция)
- [23.10.17](#231017)
- [23.10.17 - семинар](#231017---семинар)
- [23.10.24 - лекция](#231024---лекция)
- [23.10.24 - семинар](#231024---семинар)
  - [Коллоквиум по умножению автоматов](#коллоквиум-по-умножению-автоматов)
- [23.10.31 - семинар](#231031---семинар)
  - [МП-автоматы](#мп-автоматы)
- [23.11.07 - семинар](#231107---семинар)
- [23.11.14 - семинар](#231114---семинар)
- [23.11.21 - лекция](#231121---лекция)
- [23.11.21 - семинар](#231121---семинар)
  - [КС-грамматика](#кс-грамматика)
- [Мой коллоквиум о моделях. ДМП-автоматы и однозначные КС-грамматики](#мой-коллоквиум-о-моделях-дмп-автоматы-и-однозначные-кс-грамматики)
- [23.11.28 - семинар](#231128---семинар)
  - [Нормальная форма Хомского](#нормальная-форма-хомского)
- [КР](#кр)
- [23.12.05 - лекция](#231205---лекция)
- [Дела давно минувших дней](#дела-давно-минувших-дней)
  - [C1](#c1)
    - [Машина Шёнфилда](#машина-шёнфилда)
    - [ВФ, ПРФ, ЧВФ](#вф-прф-чвф)
    - [Примитивно рекурсивные отношения](#примитивно-рекурсивные-отношения)
- [24.02.06 - Лекция](#240206---лекция)
- [24.02.06 - семинар](#240206---семинар)
- [24.02.13 - лекция](#240213---лекция)
- [24.02.13 - семинар](#240213---семинар)
  - [Оператор минимизации](#оператор-минимизации)
  - [Частично вычислимая функция](#частично-вычислимая-функция)
  - [Ограниченная минимизация](#ограниченная-минимизация)
- [24.02.20 - лекция](#240220---лекция)
- [24.02.20 - семинар](#240220---семинар)
- [24.02.27 - лекция](#240227---лекция)
- [24.02.27 - семинар](#240227---семинар)
  - [Канторовская нумерация](#канторовская-нумерация)
- [24.03.05 - семинар](#240305---семинар)
  - [Машины Тьюринга](#машины-тьюринга)
- [24.03.12 - лекция](#240312---лекция)
- [24.03.12 - семинар](#240312---семинар)
  - [Функции на машине Тьюринга](#функции-на-машине-тьюринга)
- [24.03.19 - лекция](#240319---лекция)
- [24.03.19 - семинар](#240319---семинар)
  - [Машины Шёнфилда](#машины-шёнфилда)
- [24.03.26 - семинар](#240326---семинар)
  - [Вычислимые множества](#вычислимые-множества)
- [24.04.02 - семинар](#240402---семинар)
- [24.04.09 - семинар](#240409---семинар)
- [24.04.16 - семинар](#240416---семинар)
  - [Нумерация Поста](#нумерация-поста)
- [Контрольная](#контрольная)
- [24.05.07 - семинар](#240507---семинар)
  - [Лямбда-исчисления](#лямбда-исчисления)
- [24.05.14](#240514)
  - [Числа Чёрча](#числа-чёрча)
  - [Типизированные лямбда-исчисления](#типизированные-лямбда-исчисления)


# Инфо
Лектор - Пузаренко Вадим Григорьевич

Семинаристка - Гаськова Маргарита Николаевна

[Лекции прошлых лет](https://drive.google.com/drive/folders/15iKYkDVJR-yGO-eQ-DMXjvYs1m6YACVy) (не сильно отличаются от текущих)

# 23.09.05 - лекция
Алфавит - конечное множество символов $\sum = {a_0, ..., a_n}$

Слово алфавита - любая конечная цепочка символов алфавита, включая пустое слово $\epsilon$. $\sum^*$ - все слова алфавита. $\sum^+ = \sum^* / \epsilon$

$|\alpha|$ - длина слова $\alpha$

Множество слов $L \subseteq \sum^*$ - это **язык** в алфавите $\sum$. Алфавит **конечен**, язык может быть **бесконечен**.

Конкатенация слов $u \vee w = uw$ - приписывание второго слова к первому.

Конкатенация языков - их объединение в терминах множеств.

Слово $\beta$ - подслово $\alpha$, если $\exist \gamma_1, \gamma_2 : \alpha = \gamma_1 \beta \gamma_2$

Степень слова - число его повторений. $w^n = w...w$. $|w^n| = |w|n$

Звёздочка Клини - операция, образующая из языка множество всех слов, образуемых конкатенацией слов из этого языка, включая пустое слово.

$w^R$ - обращение слова задом наперёд.

*Дописать про регулярные выражения*

# 23.09.12 - лекция
## Автоматы (*вроде бы недетерминированные, но понимаю, что к чему, слабо*)
*Пропущен огромный блок непонятного размера*

**НКА** - недетерминированный конечный автомат

Автоматы распознают слова.

Могут представлены в виде графов.

**Т. "Свойство вахтёра".** Для любого конечного НКА существует такой НКА, который имеет лишь одно конечное состояние, в которое он при этом не может вернуться. Получаем добавлением к графу одной вершины нового начального состояния и эпсилон-переходов к прежним начальным состоянием

# 23.09.12 - семинар
Регулярные выражения - набор слов и символов

## Детерминированные конечные автоматы (ДКА)
**О.** ДКА - пятёрка множеств:
- $Q$ - множество состояний
- $\Sigma$ - конечный алфавит
- $Q_0$ - начальное состояние, **одно у детерминированных автоматов**
- $\delta$ - функция перехода $\delta : Q \times \Sigma \rarr Q$, причём для детерминированных автоматов для каждого состояния должны быть все переходы 
- $F$ - множество конечных состояний ($F \subseteq Q$)

**О.** Слово $w$ в алфавите $\Sigma$ распознаётся автоматом $\A$, если под действием слова $w$ автомат переходит из начального состояния в одно из конечных.

**О.** Множество слов распознаваемых автоматом $\A$ обозн. $L(\A)$ и называется языком, распознаваемым автоматом.

Автоматы удобно изображаются в виде графов.
- Кружки - состояния
- Стрелка (галочка) около кружка - начальное состояние
- Конечное состояние - второй контур кружка
- Функции перехода - стрелки с подписями

# 23.09.19 - лекция
**Т.** Если язык $L$ распознаётся НКА, то и $L^*$ распознаётся этим НКА.

**Т.** Для любого НКА существует такой ДКА, что распознаваемые ими алфавиты идентичны

*Что-то тут было про операции над автоматами*

**О.** Произведение автоматов $(A_1 \times A_2)(F)$

*Ещё кусок*

**О.** Два слова $a, b$ эквивалентный относительно языка $L$, если при конкатенации с любым словом $c$ из данного алфавита они оба принадлежат $L$.

**О.** Два слова $a, b$ будут эквивалентный относительно ДКА $A$, если отображение их через переходы автомата равно. $\delta^*(q_0, a) = \delta^*(q_0, b)$ 

**Т. Майхилла-Нероуда.** Для языка $L$, распознаваемого некоторым ДКА, существует некоторый ДКА $A' : L(A') = L$, числом состояний этого автомата является число классов эквивалентности относительно $\equiv_L$

# 23.09.19 - семинар
Если мы не можем точно определить количество состояний, значит и построить конечный автомат для такой задачи мы не сможем.

# 23.09.26 - лекция
*Вдруг резко начали проходить регулярные выражения. У семинаристки их расположение в программе было куда логичнее*

*Теперь заговорили о грамматиках*

# 23.09.26 - семинар
Эпсилон-НКА (недетерминированный конечный автомат), а отличие от ДКА:
1. Обладает эписолн-переходами
2. Не отображает любое состояние по любой букве алфавита, при этом для одной и той же буквы может быть несколько стрелок из одного состояния (запись функции перехода преобразуется в такую: $\delta : Q \times \{\Sigma \cup \{\epsilon\}\} \rarr \Pr(Q)$)
3. Может быть несколько начальных состояний

НКА может быть и не эпсилон - достаточно убрать из него эпсилон-переходы.

**Язык регулярный**, если он задаётся регулярным выражением. Язык регулярный <=> для него можно построить ДКА и, следовательно, некоторый эпсилон-НКА.

## Детерминизация НКА
**Алгоритм детерминизации:** построим из эпсилон-НКА $A$ автомат $A'$, у которого каждое состояние пометим некоторым подмножеством состояний $A$:
1. Начальное состояние $A'$ - множество всех начальных состояний $A$ и всех состояний $A$, в которе можно попасть по эпсилон-переходам
2. Пусть в автомате $A'$ есть состояния, помеченное $q_1, ..., q_n$, нарисуем стрелку с некоторой буквой $a$ (*а потом и со всеми другими буквами алфавита*) из этого состояние в состояние, помеченное **исключительно** всем, куда можно попасть из $q_1, ..., q_n$ (*то есть если у нас есть состояния, где не хватает меток или их больше, то нужно будет добавлять новое состояние*)
3. Состояние $A'$ будет конечным, если оно помечено хотя бы одним конечным состоянием из $A$

# 23.10.03 - лекция
*Чё-то там было про грамматики - регулярные и контекстно связанные*

# 23.10.03 - семинар
**Т. О накачке** Пусть язык L распознаётся ДКА с n состояниями, то самое длинное слово, читаемое автоматов без циклов, будет длины n - 1 $\rArr$ если автомат с n состояниями распознаёт слово длины $\ge n \rArr$ в чтении слова есть цикл. Этот цикл можно повторить сколько угодно раз и слово всё также будет в L.

**Т.** Если L - эпсилон-регулярный язык, значит существует такое $n_0$ для любого слова $\lambda \in L$ такого, что $|\lambda| \ge n_0 \rArr \exist \alpha, \beta, \gamma: \beta \not = \epsilon, |\alpha\beta| \le n_0$ и $\lambda = \alpha\beta\gamma$ для которых выполняется соотношение $\alpha\beta^k\gamma \in L$ для всех $k \in \omega$ 

Часто используется для доказательства нерегулярности языка в ходе попытке доказать его регулярность по последнему утверждению

*Пример*

# Подготовка к КР
Определения:
- [$\epsilon$-НКА](#230926---семинар)
- [ДКА](#детерминированные-конечные-автоматы-дка)
- РВ - 
- [теорема о накачке](#231003---семинар)

Практика:
1. Построить ДКА
2. Построить НКА
3. [Детерминировать](#детерминизация-нка)
4. Построить регулярку
5. Теорема о накачке

# 23.10.10 - лекция
*Начало на 33 странице `lec_a3`*

*Дальше переходит на некую лекцию `a6`, которой я пока найти не смог. Там рассказывается о каких-то МП-автоматах*

# 23.10.17
*Тут была ещё одна лекция, но я в полутрансе читал ОСи*

# 23.10.17 - семинар
**Грамматика** - структура $G = (N, \Sigma, P, S)$:
- $N$ - нетерминальные символы
- $\Sigma$ - конечный алфавит терминальных символов
- $P$ - множество продукций. $P \subseteq (N \cup \Sigma)*N(N \cup \Sigma)* \rArr (N \cup \Sigma)*$ - отображает слово с хотя бы одним нетерминалом в любое слово
- $S \in N$ - начальный символ

**Контекстно свободная грамматика** - грамматика, продукции которой имеют вид $A \rarr \alpha, A \in N, \alpha \in (N \cup \Sigma)*$. То есть продукции есть только для одного нетерминала

**Контекстно свободный язык** - язык, порождаемый контекстно свободной грамматикой. Слова порождаются только **терминальными символами**.

# 23.10.24 - лекция
*Что-то про ДМП (надо для коллоквиума)*

# 23.10.24 - семинар
## Коллоквиум по умножению автоматов
ДКА, образованный произведением двух ДКА:
- Множество состояний $Q_1 * Q_2$ (то есть будет парами)
- Алфавит останется общим (спросить о разных алфавитах)
- Множество переходов - тоже пары. В каждой паре отображается переходов первое состояние из пары отображается первым переходом. Второе - вторым
- Начальное состояние - пара из двух начальных
- Конечные состояния будут произвольными парами из $Q_1 * Q_2$ (*выбираем их под нашу задачу*)

**Л.** Если упрощать, говорит о том, что для произведения ДКА также корректно определена операция $\delta*^$

**Т.** У нас есть языки 2 регулярных языка $L_1$, $L_2$. ОБъединение, пересечение и разность этих языков также будут регулярными.

1. Докажем объединение. Представим $L_1 \cap L_2$ как $\overline{L_1} \cup \overline{L_1} = \Sigma^* \\ (\Sigma^* \\ L_1 \cup \Sigma^* \\ L_2)$, а такое выражение будет регулярно по определению
   1. Второе доказательство интереснее: на основании леммы о $\delta^*$ говорим, что найдётся автомат-произведение, который распознает все слова, распознаваемые обоими языками сразу. За счёт леммы выше следует, что распознаваться слово будет только если по отдельности слова будут распознаваться отдельными автоматами
2. Для объединения мы строим автомат-произведение, распознающий все слова из каждого языка. В остальном рассуждение идентично рассуждению из пункта 1.1
3. Разность доказывается похоже на 1 + по доказанным в 1.1 и 2

# 23.10.31 - семинар
## МП-автоматы
**МП-автомат** $M = (Q, \Sigma, \Gamma, \Delta, s, Z_0, F)$ - это $\epsilon$-НКА автомат с магазинной памятью:
- Q - конечное непустое множество состояний
- Сигма - алфавит
- Гамма - алфавит магазина, который является стэковым символом
- $s \in Q$ - начальное состояние
- $Z_0$ - маркер дна - единственный 
- $F \subseteq Q$ - множество конечных состояний
- $\Delta$ - конечное подмножество от $<(Q, (\Sigma \cup \{\epsilon\}), \Gamma), (Q, \Gamma')>$

МП-автомат, что логично, видит только верхний символ из стэка.

При переходе мы можем вынуть символ (**строго один**) из автомата, ничего не делать, или добавить от одного до нескольких символов, причём если мы добавляем символы $Y_1...Y_n$, то на верху стэка будет $Y_1$

Самый распространённый вариант перехода - замена верхнего символа на слово. В таком случае весь переход будет записываться как $a, X / \alpha$ - переход по символу "а" с заменой символа X со стэка на слово альфе (на вершине стэка будет первый символ альфа)

**Конфигурация МП-автомата** - тройка $(p, \zeta, \gamma)$, где:
- $p \in Q$ - текущее состояние
- $\zeta \in \Sigma^*$ - необработанная часть слова (мы ещё не прошли по переходам с этими буквами)
- $\gamma \in \Gamma^*$ - текущее содержание магазина

ВВодятся конфигурации для того, чтобы делать переходы по словам. Они обозначаются шваброй (как значок выводимости в исчислениях предикатов, не помню, как он пишется в латехе, так что будет как импликация) с нижним индексом того состояния, в которое переходим по переходу a, добавляя на стэк вместо X слово альфа - записывается как переход между конфигурациями: $(q, a\zeta, X\gamma) \rarr (p, \zeta, \alpha\gamma)$

МНожественный переход $\rarr^*$ - все возможные переходы из одной конфигурации в другую произвольной длины.

**Т.** Если у нас есть переход между конфигурациями, то мы можем добавить в конец необработанной части слова любое слово и вниз стэка какое-то что-то

Автомату с МП соответствуют 2 языка:
- L(M) - по конечному состоянию - слово принимается, если мы попали в конечное состояние
- N(M) - по пустому магазину - слово распознается, если в результате его прохода мы получили пустой магазин, то есть даже без знака дна, который был при этом удалён последним

**В обоих случаях мы ДОЛЖНЫ пройти всё слово**

# 23.11.07 - семинар
Чтобы сделать из МП-автомата по пустому магазину, распознающего язык L, такой новый автомат, который будет распознавать также и пустое слово, нам необходимо добавить отдельное начальное состояние с переходом в само себя вида $\epsilon, Z_0/\epsilon$

# 23.11.14 - семинар
**Т.** Если у нас есть язык, распознающийся некоторым автоматом по пустому состоянию, то найдётся такой автомат, который будет распознавать тот же язык по конечному состоянию. *Делается достаточно тривиально через добавление второго маркера дна. Отдельно нужно будет доказать, что язык будет в точности такой же*

**Т.** Если у нас есть автомат по конечному состоянию, значит найдётся автомат, распознающий тот же язык, но уже по пустому магазину. *Также добавляем новое начальное состояние с новым маркером, а затем из всех конечных в прошлом состояний делаем переходы в состояние-опустошитель магазина*

**ДМП-автомат:**
1. Из одной вершины может идти не больше одного перехода по конкретному символу и верхнему символу стэка (то есть не может быть различий только в заменяемом символе)
2. По конкретной тройке состояния, символа алфавита и верхнего стэкового символа может быть либо эпислон-переход, либо см. пункт 1

**Т.** Если у нас есть регулярный язык $L$, то найдётся такой ДМП $M$, что $L(M) = L$

**Префиксный язык** - язык $L$, в котором никакое слово не является префиксом другого

**Т.** Если у нас есть ДМП-автомат $M$ для языка $L = N(M)$, то:
- $L$ - префиксный. *Доказывается через тот факт, что если $\alpha$ распознаётся автоматои и при этом язык НЕ префиксный, то должно также распознаться слово $\beta = \alpha^\gamma$, но после прохождения слова $\alpha$ магазин будет уже опустошён и автомат остановится*
- Существует также ДМП $M'$, распознающий тот же язык, но по конечному состоянию
  - *Прямое доказательство:* достраиваем также, как выше. Правила ДМП не нарушатся
  - *В обратную сторону:* из распознающего по конечному состоянию также можно получить распознающий по пустому магазину тот же префиксный язык. Достраивать эпсилон-переходы по любому символу стэка мы можем за счёт утверждения, что для префиксного языка после конечного состояния уже не должны быть распознаны ни одного символа. Отсюда мы заключаем, что из конечных состояний не должно выходить стрелок, а значит мы можем добавить эписилон-переходы в уничтожитель вида $\epsilon, X/\epsilon$ 

ДМП и МП автоматы распознают немного разные языки

# 23.11.21 - лекция
*В этот день заанонсил одну из "красных" задачек и дополнительное свойство. Обещал внести в презентацию*

# 23.11.21 - семинар
## КС-грамматика
Контекстно-свободная грамматика $(\Sigma, N, S, P)$:
- $\Sigma$ - конечное множество терминальных символов
- $N$ - набор нетерминальных символов
- $S$ - стартовый нетерминал
- $P$ - преобразования из нетерминала в терминалы и нетерминалы

**Дерево разбора**:
- Корень - начальное состояние
- Внутренние нетерминальные состояния
- Листья дерева - состояния только из терминалов
- Крона -  все листья дерева

**Нормальная форма Хомского** - грамматика, которая состоит только из продукций $A \rarr BС$ и $A \rarr d$

**Если у нас есть дерево разбора**, для грамматики $(\Sigma, N, S, P)$ в нормальной форме Хомского с кроной-цепочкой $\alpha$, то длина $|\alpha| \le 2^{n-1}$

**Т. О накачке для грамматик**. Если у нас есть контекстно свободный язык $L$, тогда найдётся такое $n_0 \in \N$, что для любого $Z \in L$ при $|Z| \ge n_0$, тогда $Z = \alpha \beta \gamma \delta \eta$:
1. $|\beta \gamma \delta| \le n_0$
2. $\beta \delta \ne \epsilon$
3. $\alpha \beta^i \gamma \delta^i \eta$ - также $\in L : \forall i \ge 0$

# Мой коллоквиум о моделях. ДМП-автоматы и однозначные КС-грамматики
**Неоднозначная грамматика** - такая грамматика $(N, T, P, S)$, для которой найдётся хотя бы одна цепочка $\alpha \in T*$, для которой найдётся больше одного дерева разбора с корнем $S$ (начальным нетерминалом) и кроной, в точности равной $\alpha$. Обращаем кванторы этого заявления и получаем определение **однозначной грамматики**, то есть для любого слова $\alpha$ из $T*$ найдётся только одно дерево разбора с корнем $S$ и кроной $\alpha$

*Дополнительное определение:* **Левое порождение грамматики** $\rArr_l$ - порождение, полученное заменой по имеющимся продукцией всегда самого левого нетерминала. Также определяется и **правое порождение**.

*Показать на доске дерево разбора для однозначной и неоднозначной грамматик*

**Т. 3.3** Для любой грамматики $(N, T, P, S)$ и для любого её нетерминала $A \in N$ и любого слова $\alpha \in T*$, $\alpha$ будет иметь 2 различных дерева разбора с корнем $A$ тогда и только тогда, когда $\alpha$ имеет 2 различных левых порождения из $A$

*Доказательство:*
- `=>` Если у нас есть 2 различных дерева, то выберем первое различие в их левом обходе и, соответственно, получим различных левые порождения $A \rarr_l^* \alpha$
- `<=` Если у нас есть 2 различных левых порождения, то, строя для них деревья разбора и дойдя до первой различной продукции, мы гарантированно получим 2 различных дерева

*Дополнительное определение:* КС-язык $L$ называется **однозначным**, если найдётся хотя бы одна однозначная порождающая его КС-грамматика. В противном случае язык будет **существенно неоднозначным**

Теперь перейдём к ДМП автоматам. Напомню, что для таких МП автоматов у нас не может быть переходов из одного состояния, различных только по изменению стэка (нет переходов $a,b/\alpha$ и $a,b/\beta$), а также не может быть эпсилон-перехода с проверкой стэка по конкретному символу, если есть переходы по тому же верхнему стэковому символу (если $\epsilon, b/X$, то не может быть $a, b/X$)

Первая теорема:
**Т. 4.3** Если для некоторого ДМП-автомата $M$ и языка $L$, $M$ распознаёт язык по пустому магазину ($L = N(M)$), то $L$ имеет однозначную КС-грамматику.

*Доказательство:*

Для доказательства будет необходимо воспользоваться обозначениями из одной из бывших ранее теорем и в общих чертах обрисовать её ход, так как это играет ключевую роль

**Подготовительная Т. 3.7:** для любого МП-автомата $M$ найдётся такая КС-грамматика $G$, что $L(G) = N(M)$

*Подготовительное доказательство:*

Определим в грамматике следующие нетерминалы:
- Стартовый символ грамматики $S$
- Символы вида $[pXq]$, где $p,q \in Q$ (состояния) автомата, а $X \in \Gamma$ (стэковый символ). Это обозначение будет показывать собой переход из состояния $p$ в $q$ с удалением из стэка символа $X$

Продукции грамматики:
- $S \rarr [q_0Z_0p]$, символ $[q_0Z_0p]$ показывает, что для порождения некоторой цепочки $\alpha$ мы пройдём из $q_0$ в $p$, выбросив из стэка $Z_0$, то есть этот символ будет обозначать переход $(q_0, \alpha, Z_0) \vdash^* (p, \epsilon, \epsilon)$
- Для правил перехода автомата вида $(r, Y_1...Y_k) \in \Delta(q, a, X)$, где $a \in \Sigma \cup \{\epsilon\}$ - внутренние переходы для распознавания символов. Конечные в таком случае будут иметь вид $(p, \epsilon) \in \Delta(q, a, X)$. Отсюда для всех состояний $r_i$ мы определим продукции в грамматике: $[qXr_k] \rarr a\space[r_0Y_1r_1]...[r_{k-1}Y_kr_k]$ - интерпретируется это так: один из путей для выталкивания из магазина символа $X$ с переходом из $q$ в $r_k$ - это прочитать символ $a$, а затем вытолкнуть символ $Y_1$ (также возможно с чтением каких-то символов) для перехода из $r_0$ в $r_1$ и так повторять до перехода в $r_k$

С этой нотацией доказательство теоремы сводится к доказательству утверждения $[qXp] \rArr^* \alpha \hArr (q, \alpha, X) \vdash^* (p, \epsilon, \epsilon)$. Доказывать в обе стороны будем по индукции:

$\lArr$ докажем из перехода возможность порождения.

**Базис:** если у нас есть переход $(p, \epsilon) \in \Delta(q, \alpha, X)$ и $\alpha \in \Sigma \cup \{\epsilon\}$ (один или ноль символов), то в грамматике будет продукция $[qXp] \rarr \alpha$

**Шаг индукции:** предположим, что конфигурация МП автомата содержит $n > 1$ переходов, тогда первый переход будет иметь вид $(q, \alpha, X) \vdash (r_0, \beta, Y_1...Y_k)$, где $\alpha = a\beta$, то есть этим переходом мы прочли один символ из слова $\alpha$ (либо провели пустой переход) и каким-то образом изменили стэк. Далее у нас будут переходы $(r_0, \beta, Y_1...Y_k) \vdash^* (p, \epsilon, \epsilon)$. Из первого перехода выводится правило $(r_0, Y_1...Y_k) \in \Delta(q, a, X)$, а значит у нас в грамматике будет и продукция $[qXr_k] \rarr a\space[r_0Y_1r_1]...[r_{k-1}Y_kr_k]$, где $r_k = p$ (в силу перехода со звёздочкой клини). Символы $Y_i$ будут удаляться из магазина поочерёдно, так как по условию мы в какой-то момент попадём в состояние $r_{i-1}$ и перейдём в $r_i$ только удалив этот символ из стэка и прочитав какое-то множество символов, которую мы обозначим за $\beta_i$ (причём $\beta = \beta_1...\beta_k$), тогда можем записать переходы в автомате для каждого $Y_i$ как $(r_{i-1}, \beta_i, Y_i) \vdash^* (r_i, \epsilon, \epsilon)$. Любое $|\beta| \le |\alpha|$, а значит для них работает индукционное предположение, а значит есть в грамматике продукция $[r_{i-1}Y_ir_i] \rArr^* \beta_i$, комбинируя все эти порождения, получаем $[qXr_k] \rArr a\space[r_0Y_1r_1]...[r_{k-1}Y_kr_k] \rArr a\space\beta\space[r_1Y_2r_2]...[r_{k-1}Y_kr_k] \rArr^* a\space\beta_1...\beta_k = \alpha$ - **доказано**

$\rArr$ докажем из порождения возможность перехода

**Базис:** если у нас есть продукция $[qXp] \rarr \alpha$, тогда это возможно лишь в случае, если $\alpha$ - один или ноль символов и у нас есть переход $(p, \epsilon, \epsilon) \in \Delta(q, \alpha, X)$, а значит $(q, \alpha, X) \vdash (p, \epsilon, \epsilon)$

**Шаг индукции:** если $[qXp] \rarr^* \alpha$ содержит $n > 1$ шагов, значит можем рассмотреть первую цепочку в последовательности $[qXr_k] \rarr a\space[r_0Y_1r_1]...[r_{k-1}Y_kr_k] \rArr^* \alpha$, значит в автомате у нас будет переход $(r_0, Y_1...Y_k) \in \Delta(q, a, X)$, теперь, действуя аналогичным образом, представим $\alpha = a\alpha_1...\alpha_k$ и при этом у нас будут определены по индукционному предположению соответствующие продукции $[r_{i-1}Y_ir_i] \rArr \alpha_i$ и переходы $(r_{i-1}, \alpha_i, Y_i) \vdash^* (r_i, \epsilon, \epsilon)$, отсюда заключаем, что $(r_{i-1}, \alpha_i...\alpha_k, Y_i...Y_k) \vdash^* (r_i, \alpha_{i+1}...\alpha_k, Y_{i+1}...Y_k)$. Комбинируя эти переходы с первым, получаем $(q, a\alpha_1...\alpha_k, X) \vdash (r_0, \alpha_1...\alpha_k, Y_1...Y_k) \vdash:* (r_1, \alpha_2...\alpha_k, Y_2...Y_k) \vdash (r_k, \epsilon, \epsilon)$, поскольку $p = r_k$, доказано, что $(q, \alpha, X) \vdash^* (p, \epsilon, \epsilon)$

***Упрощённая интерпретация:***
Приведу упрощённое доказательства существования грамматики при наличии перехода, доказательство в обратную сторону строится по очень похожему принципу.
- Если у нас есть переход $(p, \epsilon) \in \Delta(q, \alpha, X)$, где $\alpha \in \Sigma \cup \{\epsilon\}$ (один или ноль символов), то в грамматике будет продукция $[qXp] \rarr \alpha$ - это база индукции
- Если переходы по автомату распознают слово длиннее, а самих переходов $n$, то первым переходом будет $(q, \alpha, X) \vdash (r_0, \beta, Y_1...Y_k)$, где $\alpha = a\beta$ (соответствующее правило $(r_0, Y_1...Y_k) \in \Delta(q, a, X)$), отсюда получаем продукцию похожего вида ($[qXr_k] \rarr a\space[r_0Y_1r_1]...[r_{k-1}Y_kr_k]$). Каждый $Y_i$ символ в стэке будет по очереди выкинут при обработке куска слова $\beta_i$: переходом $(r_{i-1}, \beta_i, Y_i) \vdash^* (r_i, \epsilon, \epsilon)$, который будет по количеству правил перехода меньше $n$, а потому для него мы по предположению индукции можем сопоставить продукцию $[r_{i-1}Y_ir_i] \rArr^* \beta_i$. Комбинируя все получившиеся продукции получаем $[qXp] \rArr^* a\beta_i...\beta_k = a\beta = \alpha$

Теперь вспоминаем о продукции $S \rarr [q_0Z_0p]$. $S \rArr^* \alpha \hArr [q_0Z_0p] \rArr^* \alpha$. По доказанному выше заключаем, что при переходе по слову $\alpha$ в конечное состояние автомата $p$ у нас будет пустой магазин, а значит слово альфа, порождаемое грамматикой, будет также распознаваться нашим автоматом по пустому магазину.

<hr>

Теперь, опираясь на теорему 3.7 нам необходимо доказать, что такая же конструкция грамматики для ДМП-автомата задаёт однозначную грамматику, то есть для любого распознаваемого автоматом слова будет существовать лишь одно дерево разбора, значит, по теореме 3.3 достаточно доказать существование лишь одного левого порождения для любого слова из $L$.

Если ДМП-автомат распознаёт слово по пустому магазину, тогда он будет делать это, доходя до пустого магазина, единственной последовательностью переходов (в силу своей детерминированности), а значит и правило автомата, на основании которого применяется продукция, будет всегда единственным (вместо $(r, Y_1...Y_k) \in \Delta(q, a, X)$ мы можем писать $\{(r, Y_1...Y_k)\} = \Delta(q, a, X)$ и в других случаях принадлежность также будет заменяться на множество из одного элемента)

При этом само правило $\{(r, Y_1...Y_k)\} = \Delta(q, a, X)$ будет порождать множество нетерминалов ($[qXr_k] \rarr a\space[r_0Y_1r_1]...[r_{k-1}Y_kr_k]$), но в силу всё также детерминированности автомата у нас будет по одному левому порождению для **последовательных** переходов $(r_{i-1}, \beta_i, Y_i) \vdash^* (r_i, \epsilon, \epsilon)$, только одна последовательность продукций будет давать тот же результат, что и ДМП-автомат 

Говоря проще, для записи $[qXr_k] \rarr a\space[r_0Y_1r_1]...[r_{k-1}Y_kr_k]$ при всех определённых порождениях $[r_{i-1}Y_ir_i] \rArr^* \beta_i$ левым порождением мы будем получать единственное дерево разбора в силу детерминированности автомата. **Доказано**

*Нарисвоать автомат и грамматику для языка $\{a^nb^n | n > 0\}$*

<hr>

**Т. 4.4** Если для некоторого ДМП-автомата $M$ и языка $L$, $M$ распознаёт язык по конечному состоянию ($L = L(M)$), то $L$ имеет однозначную КС-грамматику.

*Доказательство:* пусть язык $LE$ - наш язык, но с дополнительным оконечным символом, тогда $LE$ будет обладать префиксным свойством, а значит найдётся ДМП автомат $M'$, распознающий $LE$ по пустому магазину. По прошлой теореме, $LE$ имеет однозначную грамматику $G'$. Модифицируем эту грамматику так, чтобы новая грамматика $G$ порождала язык $L$. Для этого переместим $E$ из терминалов в нетерминалы, а также добавим продукцию $E \rarr \epsilon$. Левые порождения грамматики $G'$ будут совпадать с левыми порождениями грамматики $G$, за исключением последней продукции удаления оконечного символа. Таким образом, имей слово 2 различных порождение в $G$, оно имело бы их и в $G'$, что приводит нас к противоречию. **Доказано**

# 23.11.28 - семинар
## Нормальная форма Хомского
1. Выводящий (порождающий) нетерминал $A$: $A \rArr^* w, w \in \Sigma^*$
2. Достижимый нетерминал $A$: $S \rArr^* aAb$
3. Полезный символ = выводящий + достижимый
4. Бесполезный = не полезный

**Т.** Если из грамматики удалить все бесполезные символы, она будет порождать тот же язык

**КС-грамматики в НФ Хомского**, если все продукции имеют вид:
- $A \rarr BC$
- $A \rarr a$
- $A \rarr \epsilon$ - для грамматик, порождающих пустое слово.

Метод перехода в НФ Хомского:
1. Разбить длинные правила. Длинным считается правило длиной больше двух. Если правило длинное, преобразуем его из $A \rarr abcd : A \rarr aB, B \rarr bcd : ...$
2. Удаление эпсилон-переходов: если есть эпсилон-переходы по нетерминалам, содержащимся внутри других правил, то эпислон-правило удаляется, а правило, где содержался этот нетерминал, лишится его. Если были другие продукции для того же нетерминала, то мы записываем версию продукции-родителя без и с нетерминалом
3. Удаляем цепные правила ($A \rarr B, B \rarr C$ преобразуется в $\A \rarr C$)
4. Замена $A \rarr Ca$ на $$
5. Удаляем бесполезные символы

# КР
Грамматики, КС-грамматики, ДМП-автоматы, МП-автоматы, лемма о накачке

# 23.12.05 - лекция
Задача на автомат: Вычисломо перечислимое множество A является максимальным, если для любого вычислимо перечислимого множества B_0, содержащего B в качестве подмножества, выполняется: 
- Любое множество, расширяющее B либо оконечно, либо разность между B_0 и B оконечна (*шта?..*)

# Дела давно минувших дней
*Ввиду... Моего прележного слушания лекция в том семестре (да и в этом) не вижу смысла писать сейчас конспекты по лекциям от ноября-декабря, поэтому рассказанный в том семестре материал будет тут*

## C1
### Машина Шёнфилда
Состоит из двух команд:
- `INC I` - увеличивает содержимое регистр `I` и счётчик команд на единицу
- `DEC I, n` - если содержимое регистр `I` больше нуля, уменьшает его на единицу и ставит счётчик команд на позицию `n`, иначе ничего не делает с `I`-м регистром и инкриментирует счётчик команд 

Машина Шёнфилда задаётся:
- Потенциально бесконечным множеством регистров, занумерованных натуральными числами и содержащих натуральные числа
- Счётчик команд - особая ячейка памяти, значение которой в начальный момент времени равно нулю
- Программа - конечное множество команд, пронумерованных натуральными числами. **Шаг машины** - выполнение команды в ячейке, равной счётчику команд. Если команды с таким номером нет, программа остановится

Любой обычной команде P может быть сопоставлен **макрос** P*. Макрос может быть использован как отдельная программа. Программа с макросами - **макропрограмма**. Макросы могут пользоваться значениями регистров, но не могут пользоваться номерами строк вне самих себя.

Пример НЕ МАКРОСА `GOTO`:
![](./lec/23-11-07%20-%20goto.png)

Пример макроса копирования:
![](./lec/23-11-07%20-%20copy.png)
Здесь мы обнуляем значения J, K, поединично переносим I в J, K, а затем из K также переносим число обратно в I

**Макросы эквивалентны**, если для одинаковых входных данных они дают одинаковые выходные данные или оба не останавливаются

**Т.** Любая макропрограмма эквивалентна некоторой программе без макросов. *Доказывается индуктивным уменьшением количества макросов на единицу с правильной заменой адресов внутри макроса и после него (с учётом вставленных программных строк)*

### ВФ, ПРФ, ЧВФ
**Функция от n аргументов будет вычислимой на машине Шёнфилда**, если в ячейках i: `1 <= i <= n` хранятся аргументы (**в остальных - нули**), а после выполнения программы P, машина завершится и в нулевой ячейке будет значение функции. Если функция не определена, машина должна работать бесконечно

Функции в машине Шёнфилда удобно использовать через макросы.

*Затем идут простейшие функции и операторы, которые можно посмотреть с [семинара](#240206---семинар)*

Частичная функция f называется **примитивно рекурсивной**, если существует последовательность таких функций f_1, ..., f_n = f, что каждая функция либо простейшая, либо вычислима из предыдущих операторами суперпозиции и рекурсии. Любая ПРФ всюду определена.

Частично вычислимая функция - функция, которая получается из простейших при помощи операторов (*см. также на [семинаре](#частично-вычислимая-функция)*)

ЧВФ называется **вычислимой**, если она всюду определена (что бывает далеко не всегда)

**Т.** Любая ЧВФ вычислима на некоторой машине Шёнфилда

<img src="./lec/23-11-07 - shyonfild_f_1.png" width="47%">
<img src="./lec/23-11-07 - shyonfild_f_2.png" width="47%">

Примитивно рекурсивными будет функции:
- `x + y`
- `x * y`
- `x^y`
- `sg(x)`
- `!sg(x)`
- `x -. y`
- `|x - y|`

**Т.** Если функция $g(\vec{x}, y)$ - ЧВФ (ПРФ), то и функции
$$
f(\vec{x}, y) = \sum_{i=0}^y g(\vec{x}, i) \\
h(\vec{x}, y) = \prod_{i=0}^y g(\vec{x}, i) \\
$$
также будут ЧВФ (ПРФ). *Доказывается через тот факт, что и сумма и произведение представимы через оператор рекурсии*

*Оператор ограниченной минимизации смотри на том же [семинаре](#ограниченная-минимизация)*

### Примитивно рекурсивные отношения
Отношение $R \in \omega^n$ называется **вычислимым (примитивно рекурсивным)**, если его характеристическая функция, равняется нулю для любой точки в множестве $R$ и единице для любой точки вне него, примитивно рекурсивна.

Для двух таких отношений определяются операции объединения, пересечения, дополнения и импликации, причём если оба отношения ПР, то и отношение, полученное как результат операций, также будет ПР.

Также достаточно тривиально определяется декартово произведение двух отношений. И также отношение, образованное этой операцией, будет ПР, если ПР его аргументы.

Отсюда делаем вывод, в частности, для бинарных отношений $=, \ne, <, >, \le, \ge$. В частности, для отношения равенства характеристической функцией будет $sg(|x - y|)$

Оператор минимизации вводится для отношений через условие равенства характеристической функции нулю (aka принадлежности отношению), причём результат минимизации для ПР отношения будет ЧВФ, а для ПР отношения и ограниченной минимизации - ПРФ.

*Далее идут примеры доказательств ПРти функций целочисленного деления, взятия остатка и разных муток с простыми числами, которые мы проходили на семинаре*

# 24.02.06 - Лекция

# 24.02.06 - семинар
**Частично вычислимые** функции - то же самое, что и **частично рекурсивные**

**Примитивно рекурсивные функции** - функции, которые за конечное число шагов можно получить из простейших функций при помощи операторов

**Простейшие функции:**
- `0(x) = 0`
- `SUCC(x) = x + 1`
- $I_m^n(x_1, ..., x_n) = x_m$ - n, m - натуральные (целые и `>= 1`), `m <= n`

**Оператор суперпозиции (`S`)**. Пусть есть частичные функции такие, `f(y1, ..., yN)`, `g1(x1, ..., xN)`, ..., `gM(x1, ..., xN)` и результатом применения оператора суперпозиции к этим функциям назовём функцию `h(x1, ..., xN)` такую, что `h(x1, ..., xN) = f(g1(x1, ..., xN), ..., gM(x1, ..., xN))`

**Оператор примитивной рекурсии (`R`)**. Пусть есть частичные функции $h(z, y, \vec{x})$ и $g(\vec{x})$, то результатом применения оператора примитивной рекурсии к этим функциям назовём функцию $f(0, \vec{x}) = g(\vec{x})$ и $f(y+1, \vec{x}) = h(f(y, \vec{x}), y, \vec{x})$

Частичная функция $f : \N^k \rarr \N$ называется **примитивно рекурсивной функцией**, если существует конечная последовательность функций $f_1, ..., f_n$, которые либо простейшие, либо получаются из функций с меньшими номерами одним из операторов `S` либо `R`

Операторы суперпозиции и примитивной рекурсии дают нам всюду определённые функции

# 24.02.13 - лекция
*Тут была лекция C6*

# 24.02.13 - семинар
## Оператор минимизации
Пусть есть частичная функция $g(z, \vec{x})$. В результате применения оператора мимимизации $M$, получаем функцию $f(x)$ такую, что $f(x) = y \hArr \forall i < y$ ($g(i, x)$ определена и не равна нулю) и $g(y, x) = 0$

$f(\vec{x}) = \mu y (g(y, x) = 0)$ - так полностью записывается оператор минимищации

Например:
$$
g(y, x) = y - x \\
M: \\
f(x) =
$$

## Частично вычислимая функция
Частичная функция $f$ называется **частично вычислимой функцией** (ЧВФ), если принадлежит наименьшему классу, содержащему простейшие функции и замкнутому относительно суперпозиции, примитивной рекурсии и минимизации

Доказать частичную вычислимость функции:
$$
f(x) = \sqrt{x}
$$
*А дальше смотри картинки*

## Ограниченная минимизация
Функция $f(\vec{x})$ получается из функции $g(\vec{x}, y)$ и $h(\vec{x})$ с помощью ограниченного $\mu$-оператора, если $\mu y (g(\vec{x}, y) = 0)$ определено для всех $\vec{x}$ и значение $\mu y \le h(\vec{x})$, тогда $f(\vec{x}) = \mu y (g(\vec{x}, y) = 0)$

Если $g(\vec{x}, y) \ne 0$ для всех $y \le h(\vec{x})$, то $f(\vec{x}) = h(\vec{x}) + 1$

Записывается ограниченное $\mu$ так:
$$
\mu y \le h(\vec{x})(g(\vec{x}, y) = 0)
$$

*Говоря по-человечески, мы ищем значение не ограниченно далеко вверх, а до какого-то значения, определяемого функцией $h(\vec{x})$. Если условие $g(\vec{x}, y) = 0$ при таких значениях не было удовлетворено, то мы результатом оператора будет $h(\vec{x}) + 1$*

# 24.02.20 - лекция

# 24.02.20 - семинар
Если $f$ получается из ПРФ $g$ и $h$ с помощью оператора ограниченной минимизации, то $f$ - ПРФ

Доказывается через тот факт, что мы можем представить $f$ как:
$$
f(\vec{x}) = \sum_{i=0}^{h(\vec{x})} sg(\prod_{j=0}^i g(\vec{x}))
$$
*Подобрав примеры, достаточно легко заметить, что функция крайне элегантна*

`x div y` - ЧВФ. Деление на ноль не опр.

Если мы используем оператор огр. минимизации, то `x div y` станет ПРФ, но при этом `x div 0 = x`

Доказать, что функции ПРФ:
1. `x mod y`: `f(x, y) = x -. (x div y)*y`
2. `divs(x)` - число делителей `x`. `divs(0) = 0`
3. `pi(x)` - число простых чисел меньше или равных `x`
4. `p(x)` - `x`-е простое число

# 24.02.27 - лекция

# 24.02.27 - семинар
## Канторовская нумерация
Канторовская нумерация `C(x, y)` отображает $\N^2$ в $\N$ и делает это биективно 

Рядами в поле таких чисел будут нумероваться по побочным диагоналям, начиная обход с верхнего левого угла.

Количество рядов до точки `(x, y) = x + y`

Сумма точек до ряда с точкой `(x, y) = (x + y + 1)(x + y)/2`

Номер точки (собственно, канторовская функция) $C(x, y) = \frac{(x + y + 1)(x + y)}{2} + x$

# 24.03.05 - семинар
Основной смысл канторовской нумерации в том, что мы можем осуществлять взаимно однозначное соответствие между $\N^2$ и $\N$, что позволяет оперировать нам с парами, как обычными числами. В более общем случае мы можем взаимно отобразить $\N^n$ в $\N$, рекурсивно применяя канторовскую нумерацию к первым двум аргументам

## Машины Тьюринга
У машины Тьюринга есть:
- Внешний алфавит (зачастую рассматриваем символы `0` и `1`)
- Набор внутренних состояний $\{q_0, q_1, ..., q_s\}$
  - $q_1$ - начальное состояние, с которого машина начинает свою работу
  - $q_0$ - конечное состояние, в котором машина останавливается
- Программа - конечный набор команд следующего вида:
  - `q_i a_j -> q_k a_l` - находясь в `q_i` при значении `a_i` в указателе
  - `q_i a_j -> q_k a_l R`
  - `q_i a_j -> q_k a_l L`

Более наглядное представление:
- У машины Тьюринга есть лента, бесконечная в обе стороны, в ячейках которой содержатся символы внешнего алфавита. Когда мы сдвигаемся в пустую ячейку, мы автоматически пишем туда нулевой символ.
- Есть указатель, который смотрит на конкретную ячейку. Мы знаем только символ в ней
- Номер состояния. В начальный момент единица

Команды в программе **могут располагаться в каком угодно порядке**. Порядок их исполнения будет определяться условиями слева от стрелки

**Машинное слово** описывает состояние машины Тьюринга. Состоит из состояния ленты, указателя на ленту и текущего состояния. Записывается как строка из всех значений ленты, а перед тем, на которое сейчас указывает указатель, пишется текущее состояние `q_i`

# 24.03.12 - лекция
*Ну это мем*

# 24.03.12 - семинар
## Функции на машине Тьюринга
Функции, вычислимые на машине Тьюринга на машине Тьюринга, в точности составляют множество ЧВФ

$f : A \rarr \N, A \subseteq \N^k$ правильно вычислима на машине Тьюринга, если $\forall x_1, ..., x_k$
1. Если $f(x_1, ..., x_k) \downarrow$, то $q_1 0 1^{x_1} 0 ... 0 1^{x_k} \rArr_Т = q_0 0 1^{f(x_1, ..., x_k)} 0 ... 0$
2. Если $f(x_1, ..., x_k) \uparrow$, то машина Тьюринга бесконечно работает не выходя за левый край

# 24.03.19 - лекция

# 24.03.19 - семинар
## Машины Шёнфилда
*Общую инфу смотри [тут](#машина-шёнфилда)*

При запуске в регистрах начальные данные, а в счётчике команд ноль

Остановка при попадании в счётчик команд номера не существующей команды **всегда будет правильной**, то есть мы не можем просто завершиться на произвольном месте, если в вычислении ошибка - мы должны зациклиться

# 24.03.26 - семинар
## Вычислимые множества
Пусть $P(x_1, ..., x_n)$ - предикат

**О.** $P(\vec{x})$ - вычислимый предикат, если вычислима его характеристическая функция:
$$
\chi_p(\vec{x}) = \begin{cases}
  0, p(\vec{x}) = 1 \\
  1, p(\vec{x}) = 0
\end{cases}
$$

**Вычислимая функция** - всюду определённая ЧВФ

**О.** $P(\vec{x})$ - примитивно рекурсивный предикат, если $\chi_p(\vec{x})$ - ПРФ

Повторим соотношение классов функций: ПРФ $\subset$ ВФ $\subset$ ЧВФ

$A \subseteq \N^k$ - вычислимое множество (либо ПРФ), если его $\chi_A(\vec{x})$ - вычислимая характеристическая функция (либо ПРФ). Определяется эта характеристическая функция таким же образом

# 24.04.02 - семинар
**Тезис Чёрча** - если вам кажется, что функцию можно вычислить, значит её можно вычислить на машине Тьюринга

**Вычислимо-перечислимые множества (ВПМ)** - *есть от 8 до 13 определений, тут приведём 2 из них:*

**Первое определение ВПМ**: $A \subseteq \N^k$ - ВПМ, если $\vec{x} \in A \hArr \phi(\vec{x}) \downarrow$ и $\phi(\vec{x})$ - ЧВФ (то есть $A$ - множество определения функции $\phi$)

Любое вычислимое множество является вычислимо-перечислимым (**обратное не верно**). Доказывается определение такой $\phi(\vec{x}) = \frac{1}{\overline{sg}(\chi_A(\vec{x}))}$

**Второе определение ВПМ**: $A \subseteq \N^k$ - ВПМ $\hArr \exist f(\vec{x}, y)$ - ПРФ такая, что $A = \{\vec{x} | \exist y : f(\vec{x}, y) = 0\}$ 

# 24.04.09 - семинар
**Универсальная функция**

$K$ - произвольный счётный класс $k$-местных ЧФ

$h(t, x_1, ..., x_k)$ - **универсальная функция** класса $K$, если:
- $\forall t_0 \in \N : h(t_0, x_1, ..., x_k) = f(x_1, ..., x_k)$ и $f \in K$
- $\forall f \in K : \exist t_0 \in \N : h(t_0, x_1, ..., x_k) = f(x_1, ..., x_k)$

*Повторим:* $C(x, y)$ - канторовская нумерация

$T^2(x,y)$ - произвольная универсальная ЧВФ для класса одноместных ЧВФ (на лекции доказывалось, что такие существуют всегда)

$K^2(x_0, x_1) = T^2(l(x_0), C(r(x_0), x_1))$ - **клиниевская нумерующая функция**

Если $f(x) = K^2(m, x)$ для некоторого $m$ и всех $x$, то $m$ - **клиниевский номер функции $f$** и обозначается $\varkappa_m = f$

Отображение $\varkappa : \N \rarr PCF_1$ ($PCF_1$ - семейство всех одноместных ЧВФ) - называется клиниевской нумерацией

**Т.** S-m-n теорема (теорема о параметризации). Для любых $m,n \ge 1$ существует $m+1$-местная инъективная вычислимая функция $S_n^m$ такая, что:
$$
\varkappa_e^{m+n}(y_1, ..., y_m, x_1, ..., x_n) = \varkappa^n_{S_n^m(e, y_1, ..., y_m)}(x_1, ..., x_n)
$$
Для всех $e, y_1, ..., y_m, x_1, ..., x_n \in \omega$

**Теорема о неподвижной точке**. Для каждой $m+1$-местной ЧВФ $h$ найдётся $m$-местная инъективная функция $g$ такая, что:
$$
\varkappa^n_{h(y_1, ..., y_m, g(y_1, ..., y_m))}(x_1, ..., x_n) = \varkappa^n_{g(y_1, ..., y_m)}(x_1, ..., x_n)
$$

**Частный случай для любой унарной ЧВФ** $h$ найдётся число $a$ такое, что:
$$
\varkappa^n_a(x_1, ..., x_n) = \varkappa^n_{m+1}(x_1, ..., x_n)
$$

# 24.04.16 - семинар
**Т. Райса** Если $A$ - непустое множество и $\varkappa^{-1}(A) \subset PCF_1$, значит $A$ - не вычислима

## Нумерация Поста
Нумерация $\pi^n$ семейства $CE_n$ (вычислимо перечислимые множества подмножества $\N^n$) определяется как:
$$
\pi_x^n \equiv \delta \varkappa_x^n : \forall x \in \N
$$

**О.** Если ВПМ $A$ является $\delta \varkappa_x^n$, то число $x$ назовём **постовским номером** множества $A$ и обозначим $\pi_x^n$

То есть, если $\varkappa$ сопоставляет номеру функцию, то $\pi$ сопоставляет номеру область определения этой функции

# Контрольная
Повторить:
- Определения ЧВФ, ВМ. ВПМ
- Машина Шёнфилда
- Машина Тьюринга
- Док-ть, что функция - ЧВФ
- Доказать, что множество вычислимо
- Доказать, что множество не вычислимо (Райс)

# 24.05.07 - семинар
## Лямбда-исчисления
Эти исчисления являются основой для функционального программирования

Скобки прм лямбда-записи опускаются. Вместо `f(g)` пишем `f g` и говорим, что `f`  применяем к `g`

$\lambda x.t(\vec{a}, x)$ - правило, сопоставляющее любому иксу какое-то выражение, содержащее этот икс. $\vec{a}$ - набор констант. Лямбда называется квантором.

**Лямбда-терм (выражение)** можно определить индуктивно:
1. Переменная - лямбда-терм
2. Константа сигнатуры $\sigma$ - лямбда-терм
3. Если `A`, `B` - лямбда-термы, то `(A B)` - лямбда-терм
   - `(A B)` - оператор аппликации
4. Если $A$ - лямбда-терм и $x$ - переменная, то $\lambda x.A$ - лямбда-терм
   - Операция называется абстракцией
5. Других лямбда-термов нет

Подтерм лямбда-терма $T$ - подслово $T$, само являющееся лямбда-термом

**Свободная переменная** - переменная, которая не стоит под действием квантора $\lambda$. Обозначается $FV$

**Замкнутый терм (комбинатор)** - терм, в котором нет свободных переменных

Вхождение переменной $x$ в лямбда-терм называется **свободным**, если оно не находится по действием квантора квантора $\lambda x$

Лямбда-терм $R$ называется свободным для $x$ в $T$, если не существует свободного вхождения $x$ в $T$, находящегося под действием квантора $\lambda y$, где $y$ - свободная переменная из $R$ (*де-факто тут речь о возможности подстановки $R$ на место некого $x$ из $T$*)

Подстановка $[T]^x_R$ - Замена всех свободных вхождений $x$ на $R$. При этом $R$ должен быть свободен для $x$ в $T$

Альфа-конверсия - преобразование $\lambda x.T \rarr \lambda y.[T]^x_y$. При этом $y$ Должна быть свободна для $x$ в $T$
- $\rarr$ означает "за одни шаг переходит в ..."
- $\rArr$ означает "за конечное число шагов переходит в ..." или просто "преобразуется в ..." - рефлексивное транзитивное замыкание оператора $\rarr$

Бета-конверсия - преобразование $\lambda x.T R \rarr [T]^x_R$, при условии, что $R$ свободная для $x$ в $T$

**Аксиомы вывода схожи с конверсиями, просто заменяется стрелочка на двойную**

Также оператора $\rArr$ рефлексивен и транзитивено

Преобразования функции и аргумента при аппликации также тривиальны

**Нормальная форма лямбда-терма** - лямбда-терм, если к любому его подтерму или результату альфа-конверсии над ним не применима бета-конверсия.

**Нормальзуемый** терм - терм, приводящийся к нормальному за конечное число конверсий

# 24.05.14
## Числа Чёрча
С помощью лямбда-термов можно задать натуральные числа:
- $\underline{0} \rArr \lambda y . \lambda x . x$
- $\underline{1} \rArr \lambda y . \lambda x . (y x)$
- $\underline{2} \rArr \lambda y . \lambda x . (y (y x))$
- ...

Аппликация двух чисел Чёрча эквивалентна операции возведения в квадрат: $(\underline{n} \space \underline{m}) = \underline{n^m}$

## Типизированные лямбда-исчисления
Каждому лямбда-терму приписывается тип, это накладывает ограничения.

Предполагаем, что есть набор базовых типов

Можем строить составные типы по $\tau_0$ и $\tau_1$, обозначая тип как $(\tau_0 \rarr \tau_1)$ - называется классом всех отображений из $\tau_0$ в $\tau_1$

$x : \tau$ - $x$ имеет тип $\tau$

1. Нужно задать типы всех переменных и констант
2. Если $M : \pi \rarr \tau$ и $N : \pi$, то $(M \space N) : \tau$
3. Если $M : \tau$ и $x : \pi$, то $\lambda x . M : \pi \rarr \tau$

Лямбда-терм типизируемый, если его переменным можно приписать типы так, чтобы сам терм тоже получил тип

**Унификатор** - подстановка $S = [ \space ^{\alpha_1}_{\beta_1} \space ^{\alpha_2}_{\beta_2} \space ^{\alpha_3}_{\beta_3}]$, где $\alpha_i$ - простой тип, а $\beta_i$ - тип, не содержащий $\alpha_i$, при которой типы лямбда терма сведутся к одному типу

**Алгоритм унификации лямбда-термов:** мы должны определить функцию, выдающую подстановку:
- Если $\delta_1 = \delta_2$, то $u(\delta_1, \delta_2) = $ пустая подстановка
- Если первый тип простой, а второй не содержит первый, то $u(\delta_1, \delta_2) = [\space ^{\delta_1}_{\delta_2}]$ (если простой первый) либо $u(\delta_1, \delta_2) = [\space ^{\delta_2}_{\delta_1}]$ (если простой второй). Если в другом типе есть первый тип, то выдаём, что унификации нет
- 