========== Объектно-ориентированное программирование =======

ООП --- весьма популярная методология программирования.
В большинстве языков высокого уровня есть встроенные средства для программирования "в стиле ООП".
В языке C нет никаких средств поддержки ООП, тем не менее базовые элементы ООП используются в коде на C повсеместно.
Разумеется, раз средств языка нет, всё нужно продумывать и реализовывать самостоятельно.

((тут идут простонародные описания, на курсе ООП в будущем всё расскажут более правильно))
"Объект":
  1) хранит в себе набор некоторых данных,
  2) предоставляет методы для работы с собой.
"Класс":
  1) определяет схему данных, которые хранятся в каждом объекте (но не конкретные значения),
  2) определяет методы работы с объектами.
Для каждого конкретного класса может быть много объектов этого класса.
Каждый объект --- это экземпляр класса: в нём хранятся данные согласно схеме, прописанной в классе.
Естественно у каждого объекта данные свои собственные.

Например:
  FILE* можно считать классом файла
  stdin и stdout --- это два объекта этого класса
Разумеется, stdin и stdout отличаются, у каждого свой набор данных.

"Метод" --- это функция, которая принимает одним из аргументов указатель на объект, с которым нужно работать.
Обычно этот аргумент ставится первым, часто ему дают имена "this" или "self".

Примеры методов для FILE*:
  void fread(FILE *self, void *pointer, int size);              //(сигнатура настоящего fread отличается)
  void fwrite(FILE *self, const void *pointer, int size);       //(сигнатура настоящего fwrite отличается)
  int fprintf(FILE *self, const char *format, ...);

Обычно у класса есть особые методы:
  "конструктор" --- функция, которая создаёт новый объект класса
  "деструктор" --- функция, которая разрушает/удаляет объект, на чём его существование заканчивается
Например:
  FILE *fopen(const char *filename, const char *mode);          //конструктор FILE*
  int fclose(FILE *f);                                          //деструктор FILE*


Важная составляющая ООП --- это "инкапсуляция".
В простейшем случае инкапсуляция --- это когда пользователь класса не может напрямую читать/писать данные объекта (хотя может через методы, если таковые есть).
Обычно данные класса называются "приватными".
Например:
  Имея файл FILE*, нельзя ручками в него напрямую ничего записать  (хотя бы потому, что нигде нет объявления FILE)

Почему это важно:
1) Сложнее ошибиться: методы можно ограничить настолько, что ничего сломать просто не получится.
2) Проще понять, что от чего зависит: можно быть уверенным, что данные объекта изменяют только методы объекта.
   Без инкапсуляции данные объекта может потенциально использоваться и изменяться всюду в программе.
3) Проще изменять реализацию объекта: можно добавлять и изменять набор данных, который хранится в объекте,
   не изменяя сигнатуры и поведение методов (по сути - его интерфейса).
   Если инкапсуляции нет, то поменять что-либо в объекте, когда он повсюду используется, может быть проблематично (много изменений, большой риск багов).
   Особенно сложно, если эти объект уже используется пользователем (например в другой компании/команде разработчиков).

Надо понимать, что "нельзя" может быть в разной степени:
1) В javascript никакой поддержки приватности нет.
   Можно договориться, что если имя поля начинается с подчерка (вроде _descriptor), то оно "приватное", и обращаться к нему "нельзя".
   Естественно, это очень слабое "нельзя", т.к. нарушить его очень легко, можно даже сделать это, не заметив.
2) В Python если имя поля начинается с подчерка, то напрямую использовать его считается нехорошо, так же как в javascript.
   А вот если имя начинается в двух подчерков (__top_secret), тогда обратится к нему как обычно действительно нельзя.
   Но если очень надо, то можно обратится к нему по имени _ClassName__top_secret, так что хоть это "нельзя" и посильнее, всё равно его легко нарушить.
3) В C++ можно помечать поля структуры как "private", тогда снаружи нельзя использовать эти поля.
   Однако можно достать эти данные с помощью написания другого объявление в другой TU (например "#define private public" перед подключением хедера).
   Конечно, если пользователь так делает, то он совершенно точно будет знать, что поступает нехорошо.
   Также, поскольку в С++ (ровно так же, как в C) можно напрямую обращаться к памяти по указателю, то в принципе, пользуясь этим механизмом,
   можно получить доступ к любому приватному полю, достаточно посчитать сдвиг, по которому находится это поле.
4) В C/С++ можно не давать пользователю хедеры с объявлением структуры, но передавать ему нетипизированные указатели (void*) на структуры (форвард-декларация тоже подходит).
   Пользователь даже не видит, какие данные лежат в структуре, так что ему очень сложно данные получить или изменить.
5) В Java ООП встроено в язык, с большим упором на безопасность.
   Единственную лазейку в приватности можно отключить, и тогда получить доступ к приватному в самой Java будет невозможно.


В языке C можно указать два типичных способа реализации объектов/классов.

>>> Вариант 1.

== array.h ==
    //объявляем класс массива целых чисел
    typedef struct IntArray {
        int n, cap;
        int *arr;               //схема данных
    } IntArray;
    
    //конструктор (инициализирует данные объекта)
    void IA_Init(IntArray *self);
    
    //деструктор (объект сбрасывается к пустому состоянию)
    void IA_Clear(IntArray *self);
    
    //разные методы
    void IA_Push(IntArray *self, int x);
    int IA_Pop(IntArray *self);
    int IA_Size(const IntArray *self);
    void IA_Resize(IntArray *self, int size);

== array.c ==
    void IA_Init(IntArray *self) {
        self->n = self->cap = 0;
        self->arr = 0;
    }
    
    void IA_Clear(IntArray *self) {
        free(self->arr);
        self->arr = 0;
        self->n = self->cap = 0;
    }
    
    //... реализации прочих методов ...

== использование ==
    IntArray a, b;    //два объекта класса IntArray
    IA_Init(&a);
    IA_Push(&a, 7);
    IA_Push(&a, 13);
    IA_Init(&b);
    IA_Resize(&b, 5);
    for (int i = 0; i < 5; i++) {
        a->arr[i] = i;
    }
    IA_Clear(&a);
    IA_Clear(&b);

Про этот подход можно сказать следующее:
1) Нет никакой возможности сделать инкапсуляцию.
2) Можно создавать объект ArrayInt как локальную переменную, т.е. на стеке.
  Это устраняет одно выделение памяти в куче, а значит работает чуть-чуть быстрее.
3) Можно писать inline-методы прямо в хедере.

Из-за пункта 1 этот подход применяется редко.
Имеет смысл только для маленьких, часто используемых и редко изменяющихся классов, которые должны быстро работать.


>>> Вариант 2.

== hashmap.h ==
    typedef const void *cpvoid;
    typedef /*some-func-ptr*/ EqualFunc;
    typedef /*some-func-ptr*/ HashFunc;

    //класс хеш-таблицы
    typedef struct HashMap_s *HashMap;            //вариант А: форвард-декларация
    typedef void *HashMap;                        //вариант Б: нетипизированный указатель

    //конструктор
    HashMap HM_Create(EqualFunc ef, HashFunc hf, int size);

    //деструктор
    void HM_Delete(HashMap self);

    //разные методы
    cpvoid HM_Get(HashMap self, cpvoid key);
    void HM_Set(HashMap self, cpvoid key, cpvoid value);

== hashmap.c ==
    struct HashMap_s {
        EqualFunc fEqual;
        HashFunc fHash;         //схема данных
        uint32_t size, cnt;
        cpvoid *keys, *values;
    };

    HashMap HM_Create(EqualFunc ef, HashFunc hf, int size) {
        struct HashMap_s *self = malloc(sizeof(HashMap_s));
        self->fHash = hf;
        self->fEqual = ef;
        self->size = self->cnt = 0;
        self->keys = self->values = 0;
        HM_Alloc(self, size);
        return self;
    }

    void HM_Delete(HashMap selfy) {
        struct HashMap_s *self = selfy;
        free(self->keys);
        free(self->values);
        free(self);
    }

    //реализации прочих методов

== использование ==
    HashMap a = HM_Create(IntEqualFunc, IntHashFunc, 5);          //объект A
    HM_Set(a, &data[0], "hello");
    HM_Set(a, &data[1], "world");
    HashMap b = HM_Create(IntEqualFunc, IntHashFunc, 100000);     //объект B
    assert(HM_Get(b, &data[5]) == 0);
    HM_Set(b, &data[1], "newtable");
    HM_Destroy(a);
    HM_Destroy(b);

Иногда в typedef не пишут указатель, то есть:
    typedef struct HashMap_s HashMap;
    HashMap* HM_Create(EqualFunc ef, HashFunc hf, int size);

Что можно сказать:
1) Есть инкапсуляция.
  При этом нет особой разницы между вариантом A (указатель на необъявленную структуру) и вариантом Б (void*).
2) Каждый объект обязательно нужно создавать на куче и выделять под него память.
3) Нельзя написать метод, который будет инлайнится в месте вызова.
Благодаря инкапсуляции, это предпочтительный вариант в большинстве случаев.


=================== Время на доступ к памяти ====================

При теоретическом анализе алгоритмов полагается, что обращение к любой ячейке памяти занимает O(1) времени.
Это называется RAM (random access memory) --- можно одинаково обращаться к произвольной ячейке памяти.
С точки зрения написания программы это по-прежнему так, но работает доступ с сильно разной скоростью.

Простое правило:
  последовательный доступ к памяти (т.е. как с лентой) работает максимально быстро
  произвольный доступ к памяти (в случайном порядке) работает медленно

Разница может быть настолько велика, что кое-кто предлагает считать время произвольного доступа O(sqrt(N)), где N --- общий объём памяти:
  http://www.ilikebigbits.com/2014_04_21_myth_of_ram_1.html
(это радикальный взгляд, на экзамене так говорить НЕ рекомендуется)

Рассмотрим пару примеров.

1. Итерирование по массиву. Значение элемента - это индекс следующего элемента (как бы односвязный список на массиве).

Будем выполнять такое действие в цикле, замерять время и вычислять среднее время, потраченное на обработку одного элемента.
Исходный код на C++ (для удобства измерения времени). Здесь требуется задефайнить:
    - F - имя функции, которая заполняет массив (asc задаёт прямой порядок обхода / desc - обратный / perm - псевдослучайный);
    - N - размер массива;
    - IT - количество итераций (чем больше значение N*IT, тем точнее замеры, желательно чтобы это произведение было хотя бы 10^9).

== array.cpp ==
    #include <iostream>
    #include <chrono>
    #define Q(name) #name
    #define STR(macro) Q(macro)
    #define SF STR(F)
    int *a;
    void asc() {
        for (int i = 0; i < N; ++i) a[i] = i + 1;
        a[N - 1] = 0;
    }
    void desc() {
        for (int i = 0; i < N; ++i) a[i] = i - 1;
        a[0] = N - 1;
    }
    void perm() {
        int P = N / 4 + 1;
        for (int i = 0; i < N; ++i) a[i] = (i + P) % N;
    }
    int go() {
        int res = 0, c = 0;
        for (int i = 0; i < N; ++i) res += c = a[c];
        return res;
    }
    int main() {
        a = (int*)malloc(N * sizeof(int));
        F(); // заполняем массив
        auto start_time = std::chrono::high_resolution_clock::now();
        for (int i = 0; i < IT; ++i) go(); // IT раз обходим его в некотором порядке
        auto end_time = std::chrono::high_resolution_clock::now();
        double time_ps = (end_time - start_time) / std::chrono::milliseconds(1) * 1e6;
        double t = time_ps / IT / N;
        std::cout << "N=" << N << ", IT=" << IT << ", F=" << SF << ": " << t << "ps" << std::endl;
        free(a);
    }

Замеры показывают, что на небольшом массиве (одна или несколько тысяч элементов)
порядок итерирования не влияет или незначительно влияет на время доступа к каждому из них.
Но по мере увеличения размера массива случайный порядок обращений к элементам начинает проигрывать
по отношению к последовательному обходу.
Это происходит из-за того, что массив перестаёт целиком помещаться в кэш процессора.

2. Итерирование по матрице.

Здесь так же требуется задефайнить:
    - F - имя функции, которая обходит матрицу (ij или ji - разный порядок индексов);
    - N - размер матрицы;
    - IT - количество итераций - аналогично предыдущему примеру.

== matrix.cpp ==
    #include <iostream>
    #include <chrono>
    #define Q(name) #name
    #define STR(macro) Q(macro)
    #define SF STR(F)
    int a[N][N];
    int ij() {
        int res = 0;
        for (int i = 0; i < N; ++i) {
            for (int j = 0; j < N; ++j) res += a[i][j];
        }
        return res;
    }
    int ji() {
        int res = 0;
        for (int j = 0; j < N; ++j) {
            for (int i = 0; i < N; ++i) res += a[i][j];
        }
        return res;
    }
    int main() {
        auto start_time = std::chrono::high_resolution_clock::now();
        for (int i = 0; i < IT; ++i) F();
        auto end_time = std::chrono::high_resolution_clock::now();
        double time_ps = (end_time - start_time) / std::chrono::milliseconds(1) * 1e6;
        double t = time_ps / IT / N / N;
        std::cout << "N=" << N << ", IT=" << IT << ", F=" << SF << ": " << t << "ps" << std::endl;
    }

Зная, как хранится матрица в памяти нетрудно понять, почему функция ij будет обходить матрицу быстрее, чем ji.
Так же, как и в предыдущем примере, этот эффект будет усиливаться по мере увеличения размера матрицы.
