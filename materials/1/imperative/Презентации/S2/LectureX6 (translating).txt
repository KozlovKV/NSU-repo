================= Вариадические макросы-функции ==================

Ранее разбирались функции, принимающие произвольное количество аргументов (... / vararg, как printf/scanf).
Аналогичная возможность есть и в макросах препроцессора.

Допустим, хочется настраивать в программе логи по двум параметрам:
1) Несколько каналов (channel) логов --- по каналу на каждую систему.
   Хочется уметь включать/отключать независимо каждый канал.
2) Несколько уровней важности, например fatal(0) < error(1) < warning(2) < message(3) < debug(4) < verbose(5)
   Можно устанавливать уровень, начиная с которого все сообщения пишутся.

(см. также файл vararg_macro.c)
  #define LOG(channel, level, ...) \
    if (logEnabled[channel] && logLevel >= (level)) \
      fprintf(logFile, __VA_ARGS__); \
    else \
      ((void)0)

Здесь:
  ... --- обозначает, что макрос принимает произвольное количество дополнительных аргументов
  __VA_ARGS__ --- здесь вставляются все дополнительные аргументы через запятую

Использование:
  LOG(RENDERER, WARNING, "Cannot load material %s", name);

Замечание: есть проблема, если вместо ... передано ноль параметров.
  #define LOG(format, ...) fprintf(format, __VA_ARGS__)
  LOG("%d + %d = %d\n", 1, 2, 3);       ->      fprintf("%d + %d = %d\n", 1, 2, 3);         //OK
  LOG("hello");                         ->      fprintf("hello", );                         //error
Этот случай работает по-разному на MSVC и GCC: MSVC запятую удаляет, GCC нет.
Чтобы избежать этой проблемы, надо делать макрос так, чтобы в ... всегда приходил хотя бы один параметр.


========================= Парсинг ============================

Парсинг --- разбор текста на компьютерном языке.
Примеры компьютерных языков: C, haskell, json, html, tex, ...

Модельный пример для этой лекции --- найти значение арифметического выражения.
Разрешены целые числа, операции + - * / и скобки.
Можно вставлять в разные места произв. количество пробелов.
Унарный минус --- в качестве упражнения =)

Если смотреть порядок выполнения операций с конца:
1) Сначала вычисляется всё, что в скобках.
2) Потом выполняются умножения/деления слева направо в каждой группе.
3) Потом вычисляются сложения/умножения слева направо.

Назовём всё выражение выражением (Expr), группу умножений мономом (Monome), а значения, вычисляемые на шаге 1 атомами (Atom).

    A   A   A   A   A   A    Atom_     Atom   A   A   A   A
    |   |   |   |   |   |   /     \   /   \   |   |   |   |         //мономы и атомы в выражении
E = 3 + 5 - 4 * 7 / 8 + 5 * (3-(1)) - (2-3) * 5 / 8 / 9 + 7         //на примере
    |   |   \      _/   \_      __/   \____      _____/   |
    M   M    Monome       Monome           Monome         M

Можно описать, как должна выглядеть каждая из этих трёх сущностей (знак '|' разделяет возможные варианты):
  Expr   = Monome | Monome +- Monome | Monome +- ... +- Monone      //один или несколько мономов, разделённых знаками + и -
  Monome = Atom | Atom */ Atom | Atom */ ... */ Atom                //один или несколько атомов, разделённых знаками * и /
  Atom   = Number | ( Expr )                                        //число или выражение в скобках
Такая запись называется контекстно-свободной грамматикой (КС-грамматика) --- об этом будет потом подробно на других курсах =)


Типичная структура программы для разбора текста по КС-грамматике:

           char[]    +-------------------+       token[]        +------------+    Value
(input) -----------> | Lexer (Tokenizer) | -------------------> |   Parser   | ----------> (output)
                     +-------------------+                      +------------+
                     (лексический анализ)                    (синтаксический анализ)

Lexer читает текст как массив символов, и выделяет в нём лексемы/токены.
Parser читает текст как последовательность токенов, определяет структуру.
На выход из парсера получается некоторое значение:
  * В нашей модельной задаче это будет число типа double --- значение выражения
  * На практике почти всегда получается Abstract Syntax Tree (AST), а значит Value = Node*  (будет разъяснено далее)

Основная работа выполняется в parser, lexer нужен только для упрощения его работы.
В реальной практике lexer может:
! 1) Удалять пробелы
  2) Удалять комментарии
! 3) Выделять числа
  4) Выделять слова (в т.ч. ключевые)
  5) Выделять строки (в кавычках)
  и т.д.
В нашем примере нужны только пункты 1 и 3.

В нашей КС-грамматике арифм. выражений не описано понятие Number.
Кроме того, там есть символы + - * / ( )
Эти 7 вещей и будут токенами, которые нам надо выделить.
Кроме того, введём для удобства специальный токен eof для конца файла.
И не стоит забывать про пробелы, которые в грамматике отсутствуют и в токены не входят, их надо корректно пропустить.

Пример:
  35-..79*(5+145).-....57../.(3-2).+.7...        //пробелы показаны точками
  AAB  CCDEFGHHHI J    KK  L MNOPQ R S           //каждый токен отмечен буквой
Последовательность токенов (каждый в квадратных скобках):
  [35] [-] [79] [*] [(] [5] [+] [145] [)] [-] [57] [/] [(] [3] [-] [2] [)] [+] [7] [eof]
В нашей задаче достаточно возращать каждый токен как строку, а [eof] --- как пустую строку.


Есть два стиля реализации Lexer и Parser:
1) Получить на вход массив всех данных (содержимое всего файла или массив всех токенов файла), и выдать все выходные данные.
   При этом нужно хранить весь файл в памяти, что не экономично --- иногда это очень плохо (например при парсинге гигабайтных JSON данных).
2) Запрашивать входные данные (символы из файла или токены из lexer-а) по мере надобности, и забывать их после обработки.
   Примерно так работает обычный FILE*, если читать из него с помощью getc(). Так же можно спроектировать lexer и parser.

Обычно разбор текста происходит во втором стиле ("streaming").
Вся последовательность токенов НЕ хранится в памяти.
Вместо этого у Parser-а есть возможность запрашивать у lexer-а токены по одному, как будто читая из файла:
  readToken, peekToken --- прочитать и вернуть следующий токен в файле
Разница:
  peekToken --- не сдвигает текущую позицию, в следующий раз будет прочитан тот же токен
  readToken --- сдвигает текущую позицию в файле, в следующий раз будет прочитан следующий токен

Реализация tokenizer/lexer для арифметических выражений:

  //потоковое чтение текста было писать лень --- при желании можно переделать =)
  char text[...];                               //весь текст лежит здесь
  int pos;                                      //текущая позиция в тексте

  char token[...];                              //текущий токен
  char *readToken() {
    while text[pos] is space:                   //пропускаем пробельные символы ' ', '\n', '\t', и т.п.
      pos++;                                    //(см. функцию isspace из стандартной библиотеки)

    if text[pos] == 0:                          //если символ нулевой
      strcpy(token, "");                        //то это коней текста
      return token;                             //возвращаем токен [eof]

    if text[pos] in {'+','-','*','/','(',')'}:
      token[0] = text[pos++];                   //это простой односимвольный токен
      token[1] = 0;                             //копируем его в token и возвращаем
      return token;
    
    int left = pos;                             //остался один случай: целое число
    while text[pos] is digit:                   //токен продолжается, пока идут цифры
      pos++;                                    //(см. функцию isdigit из станд. библ.)
    memcpy(token, text + left, pos - left);     //копируем токен
    token[pos - left] = 0;
    return token;                               //и возвращаем
  }

Как написать peekToken:
  int oldPos = pos;
  readToken();
  pos = oldPos;
  return token;
Можно наоборот написать peekToken, а readToken реализовать через него.


Parser для арифметических выражений.
Нужно написать по функции на каждую сущность, определённую в грамматике:
  ParseExpr --- читает выражение, записанное далее
  ParseMonome --- читает моном, записанные далее
  ParseAtom --- читает атом, записанный далее

Чтобы функции верно работали, нужно определить соглашения и точно их придерживаться:
  1) Вызывать ParseX можно, если в тексте сущность X записана начиная с текущей позиции pos.
  2) В момент завершения ParseX текущая pos должна находится сразу после конца прочитанной сущности X.
  3) Возвращаемое значение ParseX должно быть равно значению прочитанной сущности.

Пример (вызов ParseMonome):
  
  3 + 4 * (3 - 5 * (7 - 3) / (5) + 7) / 3 + 5 * 4
              | --> --> --> --> |
             pos               pos
         (до вызова)      (после вызова)

                returns 5*(7-3)/5 = 4

Реализация:

  double ParseExpr() {
    double res = ParseMonome();                 //в любом случае выражение начинается с монома
    while peekToken() in {'+', '-'}:            //выражение продолжается, пока после монома идёт плюс или минус
      oper = readToken();                       //читаем и запоминаем знак операции (плюс или минус)
      double add = ParseMonome();               //разбираем идущий далее моном, запоминаем его значение
      res = oper(res, add);                     //выполняем над res и add операцию oper, запоминаем в res
    return res;                                 //когда выражение закончится, в res будет его значение
  }

  double ParseMonome() {
    //пишется аналогично ParseExpr, только:
    //  Monome меняется на Atom
    //  Expr меняется на Monome
    //  + и - меняются на * и /
    ...
  }

  double ParseAtom() {
    if peekToken() == '(':                      //вариант 1: это выражение в скобках
      readToken();                              //не забываем прочитать скобку!
      double res = ParseExpr();                 //рекурсивно разбираем выражение
      readToken();                              //не забываем прочитать скобку!
      return res;
    else:
      return atoi(readToken());                 //вариант 2: это целое число
  }

Важно помнить о соглашениях, которые мы сами себе установили.
Вот так работать не будет:
  double ParseAtom() {
    if peekToken() == '(':
      readToken();
      double res = ParseExpr();
      //нам ведь закр. скобка не нужна, может её и не читать? =)
      return res;
Скорее всего из-за этого все вызовы выше по стеку будут делать что попало, ответ будет неверный, и отладить будет непросто.


Время работы алгоритма: O(L), где L --- длина текста.
Доказательство:
  Нужно сложить по всем вызовам функций ParseX время без учёта рекурсивных подвызовов.

  Рассмотрим все положения, через которые проходит pos (это "перегородки" между соседними токенами).
  Пропишем в каждом положении все вызовы ParseX на стеке, которые хоть что-то в этот момент сделали.

  Пример:

        2 * 6 - 1 * ( 3 - 5 * 7 + 5 ) + ( ( 3 - 5 ) * ( 7 * 9 ) ) / 5 + 3
       E.....E_E.....................E_E.............................E_E.E  \
       M.M_M.M M.M_M.................M M.........................M_M.M M.M  | вне скобок (уровень 0)
       A_A A_A A_A A_A.............A_A A_A.....................A_A A_A A_A  /
                     E.E_E.....E_E.E     E.....................E            \
                     M.M M.M_M.M M.M     M.........M_M.........M            | внутри скобок (уровень 1)
                     A_A A_A A_A A_A     A_A.....A_A A_A.....A_A            /
                                           E.E_E.E     E.....E              \
                                           M.M M.M     M.M_M.M              | внутри двух скобок (уровень 2)
                                           A_A A_A     A_A A_A              /

  Здесь стек вызовов расположен вертикально.
  Буква показывает, что в этом месте соответствующий вызов сделал какую-то работу (потратив O(1) времени).
  Символ '_' показывает, что здесь вызов прочитал токен.
  Символ '.' показывает, что вызов в этот момент лежат на стеке в неактивном состоянии (не тратя время).

  Полное время всех вызовов пропорционально общему количеству букв на картинке.
  Заметим, в каждом положении приписано не более 4 букв --- а значит общее время работы линейное.
  Больше 4 букв в столбце быть не может, потому что:
    1) Рекурсивные вызовы идут по кругу: ParseExpr -> ParseMonome -> ParseAtom -> ParseExpr -> ...
    2) ParseAtom всегда читает один токен в самом начале своей работы.
  Это означает, что при ходе рекурсии вниз после ParseAtom все вложенные вызовы будут в следующих столбцах, и аналогично при выходе из рекурсии вверх (чтение закр. скобки).


> Abstract Syntax Tree (AST)

Обычно в процессе разбора строится дерево AST, описывающее структуру текста так, что с ней далее удобно работать в программе.
Дерево операций отлично подходит для арифметических выражений:

              [+]
             /   \
           [+]    3
          /   \__
        [-]      \_________
       /   \               \
    [*]     [*]            [/]  
   /   \   /   \           /  \
 (2)  (6) (1)  [+]        [*]  (5)
              /   \      /   \
            [-]   (5)   [-]   [*]
           /   \       /  \   /  \
         (3)  [*]    (3) (5) (7) (9)
             /   \
           (5)   (7)

Чтобы его построить, в качестве возращаемого значения (Value) надо возвращать AST-дерево.
В терминах языка C это означает, что все функции ParseX возвращают Node* --- указатель на корень дерева.
При выполнении арифметической операции в процессе парсинга нужно создать новый корневой узел с операцией, в к нему прикрепить два дерева:

   res             add                    (res-add)
   [+]             [/]                      _[-]_
  /   \           /   \      ====>        _/     \_ 
(5)   [*]       (3)   (2)              [+]         [/]   
     /   \                            /   \       /   \  
   (3)   (6)                        (5)   [*]   (3)   (2)
                                         /   \             
                                       (3)   (6)           

Такое сцепление работает за O(1), а значит парсинг по-прежнему будет работать за O(L).
В конце самый внешний вызов ParseExpr получит указатель на корень всего дерева.