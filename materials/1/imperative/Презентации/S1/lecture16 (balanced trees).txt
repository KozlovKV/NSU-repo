===================== Дерево поиска =======================

>>> Повторение: бинарное дерево поиска.
Инвариант:
  1) Структура бинарного дерева.
  2) Ключ каждой вершины больше всех ключей в левом поддереве, и меньше всех ключей в правом.

Вершина в программе:
  struct Node {
    int key;            //ключ (в данном случае целое число)
    Node *l, *r;        //указатели на левого и правого сыновей
  };
  
  Node *root;           //указатель на корень дерева

Можно выполнять операции:
  1) Find(K) --- найти вершину с ключом, равным K
    спуск вниз по условию: K < v->key => спускаемся влево, иначе вправо
  2) Add(X) --- добавить элемент X в дерево (обычно равные ключи в дереве поиска запрещаются)
    такой же спуск, на переходе в пустоту вставляем новую вершину
Обе операции работают за O(H), где H --- высота дерева.


>>> Расширяем перечень операций.

3) Remove(K) --- найти вершину с ключом K и удалить её

Сначала запускаем спуск точно так же, как в Find.
Когда вершина v с ключом v->key == K найдена, нужно рассмотреть три случая:
  а) У вершины v отсутствуют оба сына.
    В этом случае можно её просто стереть (стереть у отца указатель на неё).
  б) У вершины v ровно один сын u.
    В этом случае можно удалить вершину v, а вершину u подтянуть напрямую к бывшему отцу v.
    При этом дерево поиска остаётся корректным.
  в) У вершины v есть оба сына --- удалить её по-простому нельзя.
    Выход: нужно поменять местами вершину v с соседней (по ключу) вершиной u, после чего удалить вершину u согласно (а) или (б).
    Dершина u, соседняя по ключу справа, находится так: переходим от v к правому сыну, а от него спускаемся влево пока можно.

Детали реализации (для упрощения):
  i) Для обработки случая (в) можно просто не останавливать спуск по дереву после попадания в вершину v с ключом, равным K.
    Потому что после этого продолжающийся спуск автоматически найдёт левого или правого соседа u.
  ii) Случаи (а) и (б) можно объедить в один случай.

Время работы: O(H)

Умея выполнять операции Find, Add, Remove, дерево поиска сравнивается по возможностям с хеш-таблицей.

4) LowerBound(K) --- найти вершину с минимальным ключом, который больше или равен K.
Такую операцию можно реализовать на отсортированном массиве бинарным поиском.
Через неё можно легко выполнить Find.

Можно написать рекурсивную функцию LowerBound(v, K), которая определяет ответ в поддереве с корнем v.
Случаи:
  a) K <= v->key   => ответ либо в левом поддереве, либо в вершине v
                      вызываем LowerBound(v.left, K): если ответ не NULL, то возвращаем его, иначе возвращаем v
  б) K > v->key    => ответ должен быть в правом поддереве, возвращаем LowerBound(v.right, K)
  в) v --- пустое  => ответа нет (ключ больше всех вершин поддерева)

В каждом случае достаточно делать один рекурсивный вызов для сына.
Следовательно этот алгоритм спускается вниз по дереву и работает за O(H).

5) Next(v): найти следующую по порядку вершину после вершины v.

Способы реализации:
  i) LowerBound(v->key + 1);        //запускаем из корня поиск LowerBound с ключом чуть больше v->key
  ii) Прямая реализация:
    а) Если есть v->r, идём в ней и спускаемся влево до упора. Возвращаем полученную вершину.
    б) Поднимаемся вверх до тех пор, пока в очередной раз не выйдем в вершину-отца из ЛЕВОГО сына. Возвращаем полученную вершину.

Для варианта (ii) нужно хранить указатель на отца в каждой вершине (сложнее), зато полный проход по всем вершинам работает за O(N).

Заметим, что хеш-таблица принципиально не умеет выполнять LowerBound и Next быстрее, чем перебором всех элементов.
Хеш-таблица вообще никогда не сравнивает элементы на больше/меньше, поэтому никакого порядка в ней нет.
А дерево поиска по сути реализует упорядоченное по возрастанию множество элементов.

Например, в C++ std::set --- это дерево поиска (ordered), а std::unordered_set --- это хеш-таблица (unordered).


================== Балансировка дерева ====================

Все операции над деревом поиска работают за O(H).
Если все элементы известны заранее, можно добавить их в дерево в случайном порядке, тогда будет H = O(log N) в среднем.
Проблема: на практике часто операции над деревом поиска идут вперемешку --- добавления и запросы на поиск чередуются.
Кроме того, иногда операции поступают в режиме online, и новые операции нельзя увидеть, пока не выполнишь старые.
В этом случае нельзя изменить порядок добавления элементов.
А значит, если они например оказались упорядочены, то будет дерево-цепочка с H ~= N, и дерево поиска станет бесполезным.

Решение проблема: добавление балансировки в дерево поиска.
Алгоритм работы с деревом поиска называется сбалансированным(balanced) / самобалансирующимся(self-balancing), если H = O(log N) всегда, независимо от входных данных/операций.
Для обеспечения этого алгоритм регулярно перестраивает дерево, чтобы его высота оставалась в пределах нормы.

Есть много способов сделать дерево поиска сбалансированным:
- AVL tree
- Red-Black tree
- (2-3)-tree
- B-tree
- Splay tree
- Treap
  ...

Рассмотрим только АВЛ-деревья.
Названы по фамилиям Советских учёных: Адельсон-Вельский и Ландис (1962).

>>> Пусть у вершины v левое поддерево имеет высоту Hl, а правое --- высоту Hr.
Заметим, что требовать Hl == Hr нельзя, т.к. этому удовлетворяет только полное бинарное дерево, а оно бывает не всех размеров.
Поэтому в AVL-деревьях в инвариант добавляется немного ослабленное требование:
  3) | Hr - Hl | <= 1
Значение (Hr - Hl) называется балансом вершины v, и в AVL-дерево оно может быть: -1, 0 или 1.

Докажем оценку для высоты AVL-дерева.
Пусть S(H) --- минимально возможное AVL-дерево высоты H.
Очевидно, что S(H) монотонно возрастает: больше высота -> больше нужно вершин
Тогда:
  S(0) = 1                      //будем считать, что пустое дерево имеет высоту -1, а одновершинное --- высоту 0
  S(1) = 2
  S(2) = 4
  S(H) = S(H-1) + S(H-2) + 1    //как минимум нужна корневая вершина и поддеревья высоты H-1 и H-2 соответственно
Легко видеть, что S(H) >= fib(H), где fib(H) --- это H-ое число Фиббоначи.
Получается N >= S(H) >= fib(H) ~= C * phi^H      (здесь phi = (sqrt(5) + 1)/2 --- золотое сечение)
Тогда H <= log(N) / log(phi) + c = O(log N)   ч.т.д.

Чтобы обеспечить выполнение инварианта, необходимо хранить в каждой вершине высоту её поддерева:
  struct Node {
    int key;            //элемент
    int h;              //высота поддерева с корнем в этой вершине
    Node *l, *r;        //сыновья --- как обычно
  };
Изменять высоту поддеревьев можно с помощью перестраивания дерева.
Чтобы было легко поддерживать высоту в актуальном виде, следует написать функцию update:
  void Update(Node *v) {
    v->h = 1 + max(v->l->h, v->r->h);     //не забудьте про случай пустых поддеревьев!
  }
При изменении структуры дерева достаточно вызывать Update для всех затронутых вершин в порядке снизу вверх.

>>> В AVL-дереве используется два типа вращений:

1) Малое/простое вращение:

      y               x
     / \             / \
    x   T3   ===>   T1  y 
   / \                 / \
 T1   T2             T2   T3

порядок обхода сохраняется: T1, x, T2, y, T3
  
2) Большое/двойное вращение:

     z                z                y
    / \              / \             /   \ 
   x   T4           y   T4          x     z
  / \      ===>    / \      ===>   / \   / \
T1   y            x   T3          T1 T2 T3 T4
    / \          / \               
  T2   T3      T1   T2

порядок обхода сохраняется: T1, y, T2, x, T3, z, T4

Всего получается четыре вращения: малое/большое влево/вправо

Детали реализации:
1) Большое вращение выполняется через два малых вращения.
  Так что писать отдельно большое вращение не нужно.
2) Не забываем, что надо обновить указатель на левого/правого сына, который указывает на корень вращаемого поддерева.
  Варианты:
    а) возвращать из функции Rotate указатель на Node* (новый корень)
    б) передавать в функцию Rotate адрес указателя Node** (как с односвязными списками).
    в) менять у нового корня и старого местами СОДЕРЖИМОЕ (ключ/значение), а указатель оставлять старым.
3) Можно избавиться от необходимости писать два зеркально симметричных случая так:
  struct Node {
    ...
    Node *ch[2]; // ch[0] --- левый сын, ch[1] --- правый сын
  };
  Node *Rotate(Node *v, int z) {
    // используем v->ch[z] и v->ch[!z]
  }


>>> Процедура перебалансировки.

В результате добавления или удаления элемента баланс может немного нарушиться: стать -2 или 2.
В таком случае нужно вернуть баланс в допустимые рамки с помощью вращений.

Пусть для вершины v верно:
1) Баланс Hr-Hl у вершины v равен 2 (случай Hr-Hl = -2 рассматривается симметрично).
2) Для всех вершин ниже v баланс в пределах допустимого (т.е. эти вершины сбалансированы).
Тогда после запуска перебалансировки должно быть верно:
1) У всех вершин в v-поддереве (включая v) баланс в рамках допустимого.
2) В результате перебалансировки высота v-поддерева либо не изменилась, либо уменьшилась на 1.

Для реализации перебалансировки можно аккуратно рассмотреть все случаи.
Известно, что Hr == Hl + 2.
Рассмотрим u --- правого сына вершины v.

Случай (а): правое поддерево у вершины u доходит на максимальной глубины (Hl + 2).

       v                      
     /   \                    
    #     u                       Называется "right-right heavy", т.к. макс. глубина в поддереве справа+справа.
    #    / \                      
    #   #   #                     Среднее дерево доходит или до Hl + 1, или до Hl + 2.
    #   #   #                 
    #   #   #                 
    #   #   #                     Случай решается малым вращением влево:
 ___#___#___#___ Hl                   вершина u переезжает на место вершины v.
        #   #                 
 _______#___#___ Hl + 1       
        ?   #                 
 _______?___#___ Hl + 2       


Случай (б): правое поддерево у вершины u НЕ доходит на максимальной глубины.

       v  
     /   \
    #      u     
    #     /  \                    Называется "right-left heavy", т.к. макс. глубина в поддереве справа+слева.  
    #    w    #   
    #   / \   #                   Среди двух средних деревьев хотя бы одно доходит до глубины Hl + 2,
    #  #   #  #                   а другое доходит либо до глубины Hl + 1, либо до глубины Hl + 2.
    #  #   #  #  
 ___#__#___#__#_ Hl
       #   #  #                   Случай решается большим вращением влево:
 ______#___#__#_ Hl + 1               вершина w поднимается вверх на место v, вершины v и u помещаются слева/справа
       ?   ?  
 ______?___?____ Hl + 2


На практике удобно написать функцию Rebalance, которая проверяет баланс,
и если он нарушен, то делает перебалансировку в нужную сторону за O(1) времени.


>>> Как выполнять операции:

Add(X):
  1) Выполняем Add как в обычном дереве поиска
  2) Поднимаемся от добавленной вершины вверх до корня, запускаем для каждой вершины перебалансировку, если нужно.

Remove(X):
  1) Выполняем Remove как в обычном дереве поиска
  2) Поднимаемся от удалённой вершины вверх до корня, запускаем для каждой вершины перебалансировку, если нужно.

Пункт 2 удобно делать на выходе из рекурсии (т.е. сразу после рекурсивного вызова)



=============================================================================================================================
=============================================================================================================================
   Ниже идёт дополнительный материал!
   1) Его не было на лекции.
   2) Его не будет на экзамене.
=============================================================================================================================
=============================================================================================================================

Обоснование (на примере Add):
  Нужно показать, что выполняемые балансировки никогда не создают баланс -3 или 3.
  Доказывается индукцией по подъёму вверх до корня.
Заметим, что когда к поддереву добавлена вершина, его высота может вырасти на 1.
Однако процедура перебалансировки либо не изменяет высоту, либо уменьшает её на один.
Тогда когда мы поднимемся на уровень выше, снова будет ситуация, что высота дерева либо не изменилась, либо увеличилась на 1.



================ Отсортированный массив ===================

Можно довольно быстро выполнять все те же операции, что есть в дереве поиска, но без дерева поиска!

1) В отсортированном массиве LowerBound/Find делается быстро бинарным поиском.

2) Когда добавляют элементы, можно складывать их в отдельный неотсортированный массив.
   При выполнении LowerBound/Find эти элементы придётся тупо перебирать --- но это не страшно, пока их мало.

3) Когда удаляют элементы, можно: в отсортированном массива помечать их как удалённые, а в неотсортированном просто удалять 
   Пока пометок удалённых элементов мало, это не замедляет сильно время работы.

Получается такая структура:

   +---+---+---+-X-+---+----+-XX-+----+----+----+----+----+-XX-+-XX-+----+     +----+---+----+
   | 2 | 3 | 5 |X7X| 9 | 12 |X14X| 15 | 19 | 27 | 28 | 30 |X32X|X38X| 39 |     | 33 | 8 | 23 |
   +---+---+---+-X-+---+----+-XX-+----+----+----+----+----+-XX-+-XX-+----+     +----+---+----+

                отсортированный массив S                                    неотсортированный массив U
         (удалённые элементы D помечены буквой X)

Реализация операций.

LowerBound(K):
  1) Делаем бинарный поиск в S чтобы найти в нём lower_bound.
  2) Если попали в удалённый элемент, смещаемся вправо, пока не наткнёмся на первый неудалённый.
  3) Делает простой обход всех элементов U, чтобы найти в нём lower_bound.
  4) Комбинируем результаты из отсортированного и неотсортированного массивов.
Время работы: T = O(log |S|) + O(|D|) + O(|U|) + O(1)

Add(X):
  Добавляем новый элемент X в конец неотсортированного массива U.
Время работы: T = O(1)

Remove(K):
  1) Выполняем поиск ключа K с помощью LowerBound.
  2) Если нашёлся элемент в отсортированной части, отмечаем его как удалённый.
  3) Если нашёлся элемент в неотсортированной части, меняем его с последним и удаляем.
Время работы: T = T_lowerbound + O(1)

Чтобы операция LowerBound работала быстро, нужно поддерживать малый размер множеств U и D.
Например, введём условие (инвариант) на малость этих множеств:
  |U| <= B
  |D| <= B
Здесь B --- это какое-то заранее выбранное число, например B = 300.

Когда инвариант нарушен, нужно "оптимизировать" структуру:
1) Удаляем из S элементы, которые помечены как удалённые.
2) Сортируем неотсортированный массив U
3) Сливаем массивы S и U вместе.
После оптимизации получается только отсортированный массив, |D| = |U| = 0.
Время работы: O(|S|) + O(|U| log |U|) + O(|S| + |U|)

Пусть требуется выполнить N операций, изначально наша структура данных пуста.
Тогда каждая операция занимает времени O(B + log N).
Каждая оптимизация занимает времени O(N + B log B), но всего им не более N/B.
Полное время работы:
  T = N * O(B + log N) + N/B * O(N + B log B) = O(N B + N^2 / B + N log N)
Нужно выбрать B так, чтобы минимизировать это время:
  B = N     =>   T = O(N^2)         никогда не оптимизируем, просто храним все элементы в рандомном порядке (медленный поиск)
  B = 1     =>   T = O(N^2)         всегда держим только отсортированный массив (медленные добавления/удаления)
  B = sqrt(N) => T = O(N sqrt(N))   средний вариант!

Получается, что надо выбрать B = O(sqrt N)   (константа подгоняется).
Тогда каждая операция работает за O(sqrt N) в амортизированном смысле.
