- [Инфо](#инфо)
- [23.09.04 - лекция](#230904---лекция)
  - [Основные понятия](#основные-понятия)
- [23.09.08 - семинар](#230908---семинар)
- [23.09.11 - лекция](#230911---лекция)
- [23.09.15 - семинар](#230915---семинар)
- [23.09.18 - лекция](#230918---лекция)
  - [Геометрическая вероятность](#геометрическая-вероятность)
  - [Колмогоровские аксиомы тервера](#колмогоровские-аксиомы-тервера)
  - [Условная вероятность](#условная-вероятность)
- [23.09.25 - лекция](#230925---лекция)
  - [Полная группа событий](#полная-группа-событий)
  - [Формула Байеса](#формула-байеса)
  - [Испытание Бернулли](#испытание-бернулли)
  - [Формула Пуассона](#формула-пуассона)
- [23.09.29 - семинар](#230929---семинар)
- [23.10.02 - лекция](#231002---лекция)
  - [Случайные величины](#случайные-величины)
  - [Биномиальное распределение](#биномиальное-распределение)
  - [Распределения Бернулли и Пуассона](#распределения-бернулли-и-пуассона)
  - [Поток событий](#поток-событий)
  - [Геометрическое распределение](#геометрическое-распределение)
- [23.10.06 - семинар](#231006---семинар)
  - [Условная вероятность](#условная-вероятность-1)
- [23.10.09 - лекция](#231009---лекция)
  - [Гипергеометрическое распределение](#гипергеометрическое-распределение)
  - [Абсолютно непрерывная функция распределения](#абсолютно-непрерывная-функция-распределения)
    - [Распределение Гаусса](#распределение-гаусса)
    - [Гамма-распределение](#гамма-распределение)
    - [Распределение Коши](#распределение-коши)
- [23.10.13 - семинар](#231013---семинар)
  - [Распределение Пуассона](#распределение-пуассона)
  - [Функция плотностного распределения](#функция-плотностного-распределения)
- [23.10.16 - лекция](#231016---лекция)
  - [Многомерные случайные величины](#многомерные-случайные-величины)
    - [Независимые случайные величины](#независимые-случайные-величины)
    - [Дискретные случайные величины](#дискретные-случайные-величины)
    - [Непрерывные случайные величины](#непрерывные-случайные-величины)
    - [Примеры многомерных распределений](#примеры-многомерных-распределений)
      - [Полиномиальное](#полиномиальное)
      - [Равномерное](#равномерное)
      - [Нормальное распределение](#нормальное-распределение)
- [23.10.20 - семинар](#231020---семинар)
  - [Функции плотности](#функции-плотности)
- [23.10.23 - лекция](#231023---лекция)
  - [Матожидание](#матожидание)
  - [Дисперсия](#дисперсия)
- [23.10.27 - семинар](#231027---семинар)
  - [Матожидание и дисперсия](#матожидание-и-дисперсия)
- [23.11.03 - семинар](#231103---семинар)
  - [Матожидание и дисперсия распределение Пуассона](#матожидание-и-дисперсия-распределение-пуассона)
  - [Для равномерного распределения](#для-равномерного-распределения)
- [23.11.10 - семинар](#231110---семинар)
  - [Задача 2 из варианта физфака (фотки)](#задача-2-из-варианта-физфака-фотки)
  - [Центральная предельная теорема](#центральная-предельная-теорема)


# Инфо
Препод - Рогозинский Сергей Валентинович

Семинарист - Насибулов Егор Андреевич

[Какой-то Классрум от 19-ГО, МАТЬ ЕГО, ГОДА](https://classroom.google.com/u/3/c/MTQ0Mzk0OTQyMjg5?pli=1)

# 23.09.04 - лекция
*Спустя 12 минут жоской преамбулы ни о чём, перешли к содержанию, которое тоже особо не нужно*

*Преамбула продолжается... Соответственно*

*Ещё 4 минуты прошло и... Вроде бы начали*

*Нет, не начали*

*Загадка от Жака-Фреско: какова вероятность начала лекции?* **$10^{-42}$**

*Для примера с автобусами не хватает [Вахтанга](https://www.youtube.com/shorts/9gy5TdhxlHU)*

*А у меня ведь правда есть таро...*

*Мораль кулстори: если контора требует от вас аспирантуры, вам не нужна такая контора... Тем временем позади 37 минут*

*Пожалуйста, не говори про используемые книги! Не надо!.. Это самое... Ну... Мы их читать не будем, соответственно. Минус половина пары*

*Столкнёмся с этими вещами?.. С ракетами что ли? А, супер, ладно - только теоретически. Хм... А оценивать шансы РФ в СВО будем?..*

*"Взорвалась при Рогозине, при Путине причём" - хмммм. На что он намекает???*

**Вроде как из книг лучшая у Юденко...**
![Книги](./books.JPG)

*А, лол. Тут в списке нет Юденко*


## Основные понятия
**Тервер** - раздел математики, изучающий математические модели случайных явлений, наблюдаемых при массовых повторениях испытаний

Тервер нужен для чёткой оценки вероятности событий и её сравнения

**Модель** - объект, отражающий важные для исследования свойства реального объекта

**Событие** - что-то, что происходит:
- Детерминированные - при определённых условиях мы получим ожидаемый результат
- Вероятностные - любой исход события не гарантирован

**Случайный эксперимент** - эксперимент, результат (исход) которого нельзя предсказать однозначно. Тервер изучает случайные эксперименты, удовлетворяющие условиям:
1. Эксперимент можно повторить в одинаковых условиях достаточно много раз
2. Исход A с увеличением количества повторений стремится к некоторому устойчивому числу относительно общего количества повторений эксперимента - то есть обладает **статистической устойчивостью**

**Случайность** - философское понятие. *Расходимся*

Изучение тервера бустили страховой бизнес, демография, статистика.

*Начинать военную спецоперацию против галлов **НЕ СТОИТ***

# 23.09.08 - семинар
Элементарный исход - взаимоисключающие простые исходы (то есть несовместные), которые при этом не могут быть разделены на более мелкие события. ОБъединение всех элементарных исходов даёт нам всё пространство исходов.

Вероятность события A - $P(A)$ - доля исходов, соответствующих событию A от общего числа исходов

Для независимых событий $P(AB) = P(A) * P(B)$.

$A|B$ - наступление события $A$ после события $B$
- $P(A|B) = \frac{P(AB)}{P(B)}$ - условная вероятность
- $P(B|A) = \frac{p(BA)}{P(A)}$ ($P(AB) = P(BA)$, чего нельзя сказать об $P(A|B)$ и $P(B|A)$)

Вероятность того, что произойдёт одно из событий $A,B$: $P(A + B) = P(A) + P(B) - P(AB)$

Элементарная комбинаторика:
- Перестановки $P_n = n!$
- Размещения $A_n^k = \frac{n!}{(n-k)!}$ - комбинация длиной k из множества длины n. Важен порядок
- Сочетания $C_n^k = \frac{a_n^k}{P_k} = \frac{n!}{k!(n-k)!}$

# 23.09.11 - лекция
Множество (пространство) элементарных событий обозначается $\Omega$

Говорят, что событие $A \subset \Omega$ произошло, если произошло хотя бы одно элементарное событие $\omega \in A$

**Классификация событий:**
- Достоверное событие - обязательно происходит при повторении опыта. $\Omega$ - достоверное
- Невозможное событие - никогда не происходит при повторении опыта. обозначается $\emptyset$
- Случайное событие

Событие $A$ **включено** в $B$: $\hArr \forall \omega \in A : \omega \in B$

Если $A \subset B \rArr A$ **влечёт** $B$

Событие $A, B$ **равны** $\hArr A \subset B$ и $B \subset A$

Умножение (пересечение), сложение (объединение) и вычитание событий происходит также, как в алгебре множеств и обозначается аналогично (*это, кстати, и для многих записей выше справедливо*)

**Несовместные события** - такие $A, B$, что $AB = \emptyset$

Вероятность определяется множеством разных методов:
- Субъективно
- Логически
- Частотно - частота появления данного исхода в длинной серии
- Классическое определение - соотношение благоприятных исходов к общему числу исходов
- Геометрическое - определение для континуального пространства элементарных событий
- Для общего случая 

# 23.09.15 - семинар
**Независимые события** - вероятность одного события не зависит от вероятности другого.

Вероятность происшествия двух независимых событий $P(AB) = P(A) * P(B)$

Но на самом деле определение множества независимых событий таково: множество событий $A = {a_1, ..., a_n}$ - независимое $\hArr \forall {a_{n1}, ..., a_{nk}} \subset A : P(a_{n1}, ..., a_{nk}) = P(a_{n1}) * ... * P(a_{nk})$

Если нужно выбрать из `n` `k` вариантов и `l` из `m`, то мы получаем формулу для комбинаций:
$$
\frac{C_n^k C_m^l}{C_{n+m}^{k+l}}
$$
**Важно!** Речь тут не о простом суммировании индексов. Фишка в том, что в знаменателе перестановки из общей мощности множество по мощности общей выборки. Это важно потому, что для некоторых подсчётов могут появиться дополнительные перестановки (например, количество способов выбора масти)

# 23.09.18 - лекция
## Геометрическая вероятность
**Геометрическая вероятность** заключается в бросании некой материальной точки в область $\Omega$. Вероятность попадания в область $A \subset \Omega$ обозначается $P(A) = \mu(A) / \mu(\Omega)$, где $\mu$ - мера области события. Условия организации пространства $\Omega$ позволяют утверждать, что выбор любой точки в нём **равновозможен**

## Колмогоровские аксиомы тервера
В качестве события должны рассматриваться только такие подмножества множества $\Omega$, операции над которыми приводят снова к событиям (*то есть область событий замкнута*)

Алгеброй $F$ называется **непустой класс подмножеств множества $\Omega$**, которые удовлетворяют условиям:
1. $\Omega \in F$
2. $A \in F \rArr \overline{A} \in F$
3. $A_1, ..., A_n \in F \rArr \cup_1^n A_i \in F$

Из этого определения мы можем вывести вероятностное пространство $<\Omega, S, P>$, где $\Omega$ - множество элементарных событий, $S$ - $\sigma$-алгебра, $P$ - функция, сопоставляющая каждому событию $A \in S$ число, называемое его вероятностью:
1. $0 \le P(A)$
2. $P(\Omega) = 1$
3. Для попарно непересекающихся $A_i, A_j$: $P(\cup_1^{\infty} A_i) = \sum_1^{\infty} P(A_i)$

## Условная вероятность
**О.** Вероятность события $A$ при условии, что произошло событие $B$: $P(A|B) = \frac{P(AB)}{P(B)}$

Универсальная формула для вероятности происшествия нескольких событий $P(AB) = P(A)P(B|A) = P(B)P(A|B)$

Таким же образом задаётся формула для произвольного количества событий: $P(A_1, A_2, A_3, ...) = P(A_1)P(A_2|A_1)P(A_3|A_1A_2)...$

**Независимые события** - события, вероятность которых никак не зависит друг от друга. Для них $P(A|B) = P(A)$ и наоборот. $\rArr P(AB) = P(A)P(B)$

# 23.09.25 - лекция
## Полная группа событий
**Полная группа событий** - группа попарно несовместных событий, то есть выполняются условия:
1. $\forall i,j : H_iH_j = \emptyset$
2. $\sum H_i = \Omega$

Если ${H_i}$ - полная группа и нам известны вероятности $P(H_i)$ и $P(A|H_i)$, то вероятность интересующего нас события $A$ будет $P(A) = \sum_{i=0}^n P(H_i)P(A|H_i)$

## Формула Байеса
Предположим у нас имеется полная группа ${H_i}$, каждое H в данном случае называется **гипотезой**, а $P(H_i)$ - его **априорная вероятность**. Если нам известные априорные вероятности и условные вероятности $P(A|H_i)$, то формула **апостериорной вероятности** $P(H_i|A) = \frac{P(H_i)P(A|H_i)}{P(A)}$. 

*Апостериорной обычно называется оценка пост-фактум. "Если произошло событие $A$, то какаова вероятность, что ему предшествовало именно событие $H_i$"* 

## Испытание Бернулли
**Схемой Бернулли** - эксперимент, удовлетворяющий условиям:
1. Эксперимент имеет 2 исхода ($A,\overline{A}$)
2. Эксперимент повторяется $n$ раз. При этом результат любого из экспериментов не должен влиять на любой другой
3. Вероятность двух исходов при каждом повторении исходного эксперимента одна и та же

Возьмём событие $p$ и $\overline{p} = q$

Будем считать за $P(n,m)$ - вероятность того, что при $n$ испытаниях некоторое событие произошло $m$ раз.

**Формула Бернулли:**
$$
P(n,m) = C_n^m p^m q^{n - m}
$$

*Пример:* частица пролетает мимо 6 счётчиков, каждый счётчик регистрирует частицу с вероятностью $0.8$. Частица считается обнаруженной (событие $A$), если она была замечена хотя бы двумя счётчиками. Найти вероятность события $A$.

- $p = 0.8$
- $q = 0.2$

Возьмём обратное событие $\overline{A} = A_0 + A_1$ - ни один датчик не сработал либо сработал только 1. Теперь применим формулу Бернулли 
$$
P(\overline{A}) = P(A_0) + P(A_1) = P(6, 0) + P(6, 1) = C_6^0q^6 + C_6^1pq^5 = (0.2)^6 + 6*0.8*(0.2)^5 = ... = 0.0016 \newline
\rArr P(A) = 1 - P(\overline{A}) = 0.9984
$$

<hr>

События в эксперименте Бернулли при разных $m$ **несовместны** $\rArr$ вероятность происшествия события при $n$ испытаниях от $m_1$ до $m_2$ раз = сумме их вероятностей для формулы Бернулли.

Формулу Бернулли очень больно использовать при большом количестве испытаний

## Формула Пуассона
Применяется в тех случаях, когда при **большом** количестве испытаний $n$ мала вероятность успеха:
$$
\lambda = np_n \newline
P(n, m) = C_n^m p^n q^{n-m} \rarr \frac{\lambda^m}{m!}e^{-\lambda}
$$
*Считается через формулу Бернулли и второй замечательный предел*

# 23.09.29 - семинар
**Геометрическая вероятность**

# 23.10.02 - лекция
## Случайные величины
**Случайная величина** - функция $X$, ставящая в соответствие каждому элементарному исходу $\omega \in \Omega$ число $x = X(\omega)$

[Определение функции распределения с семинара](#функция-плотностного-распределения)

Случайная величина $X$ называется дискретной, если существует конечное или счётное множество $\{x_k\}$ такое, что $\sum_{k=1}^{\infty}P(X = x_k) = 1$

*Дальше смотри там же, где и определение функции распределения*

## Биномиальное распределение
По сути, та же формула Бернулли, но немного с иной нотацией: также $n$ испытаний с вероятностью успеха $p$ и неуспеха $q = 1 - p$, но теперь мы обозначим количество успешных испытаний случайной величиной $X$ и получим формулу $P(X = k) = C_n^k p^k q^{n - k}$, также иногда пишут $X \equiv Bin(n, p)$. Через эту формулу можно построить таблицу/график распределения случайной величины $X$.

Не надо забывать об условиях биномиальных испытаний (испытаний Бернулли):
1. Только 2 исхода
2. Вероятность исходов неизменна
3. Все испытания независимы

## Распределения Бернулли и Пуассона
**Распределением Бернулли** называется испытание Бернулли при количестве испытаний = 1

**Распределением Пуассона** будто бы полностью копирует [формулу Пуассона](#формула-пуассона) с добавлением записи вида $X \equiv P(\lambda)$

## Поток событий
**Потоком событий** называется последовательность событий, которые наступают в случайные моменты времени.

**Интенсивность потока** $\lambda$ - среднее число событий за единицу времени. Если интенсивность потока - константа - и вероятность появления $k$ событий за время $t$ определяется формулой Пуассона $p_k = \frac{(\lambda t)^k}{k!}e^{-\lambda t}$, то поток событий называется **простейшим**

## Геометрическое распределение
Если проводятся независимые испытания, при который вероятность появления события $A$ - $p$, не появления - $q = 1 - p$. Если $X$ - число испытаний до первого события $A$, то вероятность, что событие произойдёт впервые на $k$-м испытании: $p_k = P(X = k) = pq^{k-1}$. Обозначается как $X \equiv Geom(p)$

# 23.10.06 - семинар
## Условная вероятность
Почти вся инфа [отсюда](#полная-группа-событий)

# 23.10.09 - лекция
## Гипергеометрическое распределение
Если из среди $N$ деталей есть $M$ стандартных, а мы хотим выбрать $n$ деталей так, чтобы среди них было $m$ стандартных (обозначим это событие за распределение $X$), то надо использовать несколько сочетаний:
- Всего вариантов выбрать $n$ изделий из $N$: $C_N^n$
- Число стандартных деталей $m$ из $M$ можно выбрать $C_M^m$ способами
- Тогда из $N - M$ нестандартных изделий требуемое количество нестандартных деталей $n - m$ можно выбрать $C_{N - M}^{n - m}$ способами

Получаем формулу $p_m = P(X = m) = \frac{C_M^m C_{N - M}^{n - m}}{C_N^n}$. Обозначается кратко такая формула как $X \equiv HG(N, M, n)$

Гипергеометрическое распределение моделирует число удачных выборок без возвращения из конечной совокупности (*что бы это ни значило... Наверное означает то, что совокупность деталей $N,M$ меняется при выборе*)

Если выборка относительно общего количества мала или выбор идёт из генеральной совокупности (*$N,M$ не меняются*), то можно использовать биномиальное распределение $X \equiv Bin(n, M/N)$

## Абсолютно непрерывная функция распределения
Если $F(x) = \int_{-\infty}^x f(u)du$, то функция распределения $F(x)$ называется **абсолютно непрерывной** (ещё её называют **непрерывной случайно величиной**), а $f(u)$ - **плотностью распределения** случайной величины $X$.

Если плотность распределения $f(x) = const, \forall x \in (a, b)$, то распределение на отрезке $(a, b)$ называют **равномерным**. Очевидно, что функция распределения в таком случае будет равномерно расти на $(a, b)$ (*то есть будет прямой*). Обозначается такая ситуация как $X \equiv U(a, b)$

**Экспоненциальное распределение** $X \equiv Exp(\lambda)$ - такое распределение, при котором плотность распределения $f(x) = \lambda e^{-\lambda x}, F(x) = 1 - e^{-\lambda x}, x > 0$, где $\lambda > 0$ - параметр распределения.

### Распределение Гаусса
**Нормальное (Гауссовское) распределение** $X \equiv N(a, \sigma)$ - плотность $f(x) = \frac{1}{\sigma \sqrt{2\pi}}\exp(-\frac{(x - a)^2}{2\sigma^2})$, где $a, \sigma$ - параметры распределения. При $a = 0, \sigma = 1$ распределение называют **стандартным нормальным распределением**. Заменив случайную величину $X$ на $Z = \frac{X - a}{\sigma}$, мы получим нормальное распределение для $Z$

Интеграл для стандартного нормального распределения называется интегралом Лапласа:
$$
Ф(x) = \frac{1}{\sqrt{2\pi}}\int_0^x \exp(-\frac{t^2}{2})dt
$$

Интеграл Лапласса $Ф(z)$ позволяет считать вероятность $X \in (x_1, x_2)$ при нормальном распределении для заданных $a, \sigma$: $Z = \frac{X - a}{\sigma}$. $Ф(-z) = -Ф(z)$. Из этих правил получаем, что вероятность попадания случайно величины в интервал будет:
$$
Ф(z_2) - Ф(z_1) = Ф(\frac{x_2 - a}{\sigma}) - Ф(\frac{x_1 - a}{\sigma})
$$
Интеграл Лапласа не берётся, поэтому используются численные методы либо таблицы значений.

**Правило трёх сигм**: для $X \equiv N(a, \sigma)$ вероятность отдаления значения $x$ от $a$ на расстояние больше $3\sigma$ близко к нулю.

Доказывается через простые вычисления (*если с табличной XD*):
$$
P(|X - a| < 3\sigma) = P(-3 < \frac{X - a}{\sigma} < 3) = Ф(3) - Ф(-3) = 2Ф(3) \approx 0.9973
$$
**Если правило трёх сигм для неизвестного закона распределения не выполняется, есть большие основания полагать, что распределения не является нормальным**

### Гамма-распределение
Плотность:
$$
f(x) = \frac{\lambda^a}{Г(a)}x^{a-1}e^{-\lambda x}, x > 0 \newline
a > 0, \lambda > 0, \newline
Г(a) = \int_0^{\infty}x^{a - 1}e^{-x}dx = (a - 1)!
$$
*Не понимаю, зачем давать такую сложную нотацию для Гамма-функции...*

Обозначается как $X \equiv Г(a, \lambda)$

### Распределение Коши
$$
X \equiv K \newline
f(x) = \frac{1}{\pi}\frac{1}{1 + x^2} \newline
F(X) = \frac{1}{2} + \frac{1}{\pi}\arctg x
$$

# 23.10.13 - семинар
## Распределение Пуассона
[Формула Пуассона](#формула-пуассона)

*Задача:*
Вероятность, что насекомое отложит k яиц = $P_{\lambda}(k) = \frac{\lambda^k}{k!}e^{-1}$

Вероятность вылупления яйца = P. Какова вероятность, что вылупится n яиц?

Яйца вылупляются независимо, поэтому при $k \ge n$ вероятность вылупления n яиц = $P^nP^{k-1}$, причём вариантов таких ситуаций может быть биноминальное количество, то есть $C_k^n$. Домножаем это на вероятность откладывания k яиц и получаем путём сокращений и суммирований (считая k от n до бесконечности), получаем формулу $\frac{(\lambda p)^n}{n!}e^{-\lambda p}$ 

## Функция плотностного распределения
**О.** $F(x) = P(\xi < x)$ - функция распределения случайной величины. (кси случайная, икс - заданное функцией число)

$$
F(-\infty) = 0 \newline
F(\infty) = 1 \newline
$$
$F(x)$ непрерывна слева и неубывает

$f(x) = F'(x)$ - плотность распределения

Определённый интеграл функции плотности распределения даст нам вероятность попадания числа в область интегрирования, то есть вероятность для отрезка $[a, b)$ будет равна $F(b) - F(a)$ (*причём включение или не включение граничных точек не играет роли, что следует из сути определённых интегралов*).

Для дискретного распределения мы не очень хотим считать плотность через производную. Чаще мы строим табличку с иксами и вероятностями выпадения именно этих значений.

# 23.10.16 - лекция
## Многомерные случайные величины
Пусть дана тройка $(\Omega, F, P)$, где $X_i$ - случайные величины и $\forall \omega \in \Omega : X_i(\omega) \equiv X_i$, тогда $X = (X_1, X_2, ..., X_n)$ - $n$-мерная случайная величина.

Тогда совместная функция распределения для них будет $F_{X_1,...,X_n}(x_1,...,x_n) = P(X_1 < x_1,...,X_n < x_n)$. Запись нижних индексов у $F$ здесь куда более существенно, так как мы можем брать лишь некоторые случайные величины для распределения, однако при работе со всем вектором $X$ допустимо писать $F(x_1,...,x_n)$ или $F(\vec{x})$.

Основные свойства следуют из понятия распределения (его ограниченности `[0,1]`, линейности и непрерывности слева).

Отдельного упоминания заслуживает вероятность попадания в полуполосу: для случайной величины $(X, Y): P(x_1 \le X < x_2, Y < y) = F(x_2, y) - F(x_1, y)$ (*хотя и это свойство, по сути, следует из $F(x) = \int_{-\infty}^x f(t)dt$*)
<img src="./lectures/23-10-16 - property6.png" width="70%">

Аналогичным геометрическим (интегральным) образом определяется вероятность попадания в прямоугольник:
<img src="./lectures/23-10-16 - property7.png" width="70%">

### Независимые случайные величины
Случайные величины вектора $X$ будут называться **независимыми в совокупности**, если для любой перестановки $i_1, ..., i_k: F_{X_{i_1}, ..., X_{i_k}}(x_{i_1}, ..., x_{i_k}) = F_{X_{i_1}}(x_{i_1}) * ... * F_{X_{i_k}}(x_{i_k})$

**Попарно независимы** - независимы 2 любые величины из вектора $X$

### Дискретные случайные величины
Вектор $X$ может состоять из либо из дискретных, либо из непрерывных случайных величин, либо быть смешанным

![](./lectures/23-10-16%20-%202descrete.png)
*Кроме суммы по столбцу аналогично определяется сумма по ряду $p_{i.}$*

Вероятности по рядам и столбцам называются **маргинальными случайными величинами**. Для двух дискретных независимых случайных величин будет выполняться равенство $p_{ij} = p_{i.}p{.j}$

### Непрерывные случайные величины
Совместная функция распределения случайных величин будет **абсолютно непрерывной**, если $\exist f(x_1, ..., x_n) : \forall \vec{x} : F(x_1, ..., x_n) = \int_{-\infty}^{x_1}...\int_{-\infty}^{x_n} f(t_1, ..., t_n)dt_1...dt_n$.

Для этого распределения также справедливы все те свойства, что и для обычного распределения случайной непрерывной величины. Запишу лишь те, в которых будут некоторые отличия:
- $f(x_1, ..., x_n) = \frac{\delta^nF(x_1, ..., x_n)}{\delta x_1, ..., \delta x_n}$
- Маргинальные случайные величины:
  - Из лекции (*интегралов будет $n-1$ штук*):
  $$
  f(x_i) = \int_{-\infty}^{+\infty}...\int_{-\infty}^{+\infty} f(t_1, ..., t_n)dt_1...dt_{i-1}dt_{i+1}...dt_n
  $$
  - Более понятная форма записи 
  $$
  f(x_i) = \frac{\delta F(x_1, ..., x_n)}{\delta x_i}
  $$
- Независимость случайных величин в совокупности даёт выполнение равенства перемножения любой из перестановок маргинальных вероятностей совокупной вероятности
- ![](./lectures/23-10-16%20-%20continous6.png)

### Примеры многомерных распределений
#### Полиномиальное
Обобщение биномиального распределения для $K \ge 2$ типов событий, где $X_i$ - число независимых событий $i$-го типа при $N$ испытаниях. $p_i$ - вероятность появления событий типа $i$

<img width="70%" src="./lectures/23-10-16 - polynomial_n_distribution.png">

#### Равномерное
Для вектора $X = (X_1, ..., X_n)$ и области $A \subset \R^n$ с определённой мерой объёма $\mu(A)$:
$$
f(x) = \begin{cases}
  \frac{1}{\mu(A)}, x \in A \newline
  0, otherwise
\end{cases}
$$

#### Нормальное распределение
*Эту жуткую формулу просто оставлю тут скрином*
![](./lectures/23-10-16%20-%20gauss_n_distribution.png)

*Зато вот визуализация очень понятная (а потом представьте её для n-мерного пространства, лол)*:
<img width="70%" src="./lectures/23-10-16 - gauss_2_example.png">

# 23.10.20 - семинар
## Функции плотности
Если у нас есть функция плотности $f_x(x)$, а также некоторое преобразование $y = g(x)$, то мы можем выразить новую функцию плотности
$$
f_y(g(x)) = \frac{f_x(x)}{g'(x)}
$$

# 23.10.23 - лекция
## Матожидание
**Матожидание** сумма случайных величин умноженных на вероятности их выпадения
$$
EX = \sum x_ip_i
$$

Матожидание для дискретных распределений (*расчёты на [семинаре](#матожидание-и-дисперсия-распределение-пуассона)*):
- Матожидание для $X \equiv Bin(n,p)$: $EX = np$
- Матожидание для $X \equiv P(\lambda)$ (Пуассон): $EX = \lambda$

Из определения матожидания следует, что для непрерывной функции $y = g(x)$: $EY = \int_a^b f(x)g(x) dx$, где $f(x)$ - плотность функции, а $g(x)$ - определённая нами функция. Отсюда следует, что для $g(x) = x$ мы получаем $EX = \int_a^b f(x)xdx$ (*чаще всего интегралы берутся от минус до плюс бесконечности*)

Матожидание для непрерывных распределений (*считаем интегральчики и "кайфуем"*):
- Равномерное: $EX = \frac{a + b}{2}$
- Нормальное распределение с параметрами $a, \sigma$: $EX = a$
<img src="./lectures/23-10-23 - EX_gauss.png" width="80%">

- Экспоненциальное распределение с параметром $\lambda$: $EX = \frac{1}{\lambda}$
<img src="./lectures/23-10-23 - EX_exp.png" width="80%">

Свойства матожидания:
- Матожидание постоянной величины $C$: $EX = C$
- $E(CX) = C EX$
- $E(X + Y) = EX + EY$
  - $E(X - Y) = EX - EY$
- $E(XY) = EX EY$ (**для независимых случайных величин**)
- $X > Y \rArr EX > EY$

## Дисперсия
**Дисперсия** - матожидание случайной величины в квадрате минус квадрат матожидания случайной величины $DX = E(X - EX)^2 = E(X^2 - 2EX^2 + (EX)^2) =  EX^2 - 2(EX)^2 + (EX)^2 = EX^2 - (EX)^2 = \sum x_i^2p_i - (EX)^2$

**Стандартное уклонение** (среднее квадратическое) $\sigma_X = \sqrt{DX}$

Дисперсию также называют мерой рассеяния случайной величины - чем она больше, тем дальше значения могут быть от среднего (от матожидания)

<img src="./lectures/23-10-23 - DX.png" width="50%">

Аналогично матожиданию будет задаваться и дисперсия для непрерывной случайно величины с плотностью $f(x)$: $\int_a^b (x - EX)^2f(x)dx = \int_a^b x^2f(x)dx - (EX)^2$

Свойства дисперсии:
- Дисперсия постоянной случайно величины $C$ равна нулю (*что логично из самого понятия - некуда ей отклоняться*)
- $D(CX) = C^2DX$
  - $\rArr D(-X) = DX$
- $D(X + C) = DX$
- Из последних двух свойств следует: $D(aX + b) = a^2DX$
- $D(X + Y) = DX + DY$ (**для независимых величин**)
  - $D(X - Y) = DX + DY$ (*следует из вынесения множителя для дисперсии*)
- 

# 23.10.27 - семинар
Рассмотрим экспоненциальное распределение
$$
f(x) = \begin{cases}
  0, x < 0 \newline
  ae^{-ax}, x > 0
\end{cases}
F(x) = \int_0^x f(t)dt = 1 - e^{-ax}
$$

## Матожидание и дисперсия
Для обычного шестигранного кубина матожидание будет $\frac{1}{6} + \frac{2}{6} + \frac{3}{6} + \frac{4}{6} + \frac{5}{6} + \frac{6}{6} = \frac{21}{6} = 3.5$

Для кубика дисперсия составит:
$$
EX^2 = \frac{1}{6} + \frac{4}{6} + \frac{9}{6} + \frac{16}{6} + \frac{25}{6} + \frac{36}{6} = \frac{91}{6} \newline
(EX)^2 = \frac{21}{6}^2 = \frac{441}{36} \newline
\rArr DX = \frac{91}{6} - \frac{441}{36} = \frac{546 - 441}{36} = \frac{105}{36} = \frac{35}{12} \newline
$$
Другим способом:
$$
DX = \sum (i - EX)^2\frac{1}{6} = 2[\frac{15^2}{6^3} + \frac{9^2}{6^3} + \frac{3^2}{6^3}] = \newline
\frac{1}{3}[\frac{5^2}{2^2} + \frac{3^2}{2^2} + \frac{1}{2^2}] = \newline
\frac{1}{3}[\frac{25 + 9 + 1}{4}] = \frac{35}{12}
$$

# 23.11.03 - семинар
## Матожидание и дисперсия распределение Пуассона
$$
x_k = k, p_{\lambda}(k) = \frac{\lambda^k}{k!}e^{-\lambda}
EX = \sum_{k=0} k \frac{\lambda^k}{k!}e^{-\lambda} = \sum_{k=1} \frac{\lambda^{k-1}\lambda}{(k-1)!}e^{-\lambda} = \lambda \sum_{k=1} e^{\lambda}e^{-\lambda} = \lambda
$$
Теперь посчитаем дисперсию:
$$
EX^2 = \sum_{k=0} k^2 \frac{\lambda^k}{k!}e^{-\lambda} = \sum_{k=1} k \frac{\lambda^{k-1}\lambda}{(k-1)!}e^{-\lambda} = \lambda\sum_{k=1} \frac{\lambda^{k-1}}{(k-1)!}e^{-\lambda}(k - 1 + 1) = \newline
\lambda[\sum_{k=1} \frac{\lambda^{k-1}}{(k-1)!}e^{-\lambda} + \sum_{k=1} \frac{\lambda^{k-1}}{(k-1)!}e^{-\lambda}(k - 1)] = \newline 
\lambda[\sum_{k=1} e^{\lambda}e^{-\lambda} + \lambda\sum_{k=2} \frac{\lambda^{k-2}}{(k-2)!}e^{-\lambda}] = \newline
\lambda + \lambda^2 = \newline
\rArr DX = \lambda + \lambda^2 - (EX)^2 = \lambda
$$

## Для равномерного распределения
$$
EX = \frac{a + b}{2} \newline
EX^2 = \frac{a^2 + ab + b^2}{3} \newline
DX = \frac{(b - a)^2}{12}
$$

# 23.11.10 - семинар
**Ковариация случайных величин $X,Y$** - $cov(X, Y) = E((X - EX)(Y - EY))$

Коэффициент корреляции $= \rho(X, Y) = \frac{cov(X, Y)}{\sqrt{DX DY}}$

Отсюда следует, что ковариация $cov(X, X) = DX \rArr \rho(X, X) = 1$

Также для $Y = kX : \rho(X, Y) = 1$

## Задача 2 из варианта физфака (фотки)
$X$ - количество гербов для двух подбрасываний монетки
$$
X_1 = |1 - X|, X_2 = 2X
$$
Найти $\rho(X_1, X_2)$
```
X   |  0  |  1  |  2
X_1 |  1  |  0  |  1
X_2 |  0  |  2  |  4
p   | 0.25| 0.5 | 0.25

EX_1 = 0.25 + 0 + 0.25 = 0.5
EX_2 = 0 + 1 + 1 = 2
DX_1 = 0.5 - 0.5^2 = 0.25
DX_2 = 4*0.5 + 16*0.25 - 4 = 2 + 4 - 4 = 2
cov(X_1, X_2) = E((X_1 - 0.5)(X_2 - 2)) = 0.25((1-0.5)(0-2)) + 0.5((0-0.5)(2-2)) + 0.25((1-0.5)(4-2)) = -0.25 + 0 + 0.25 = 0
=> ro = 0
```

## Центральная предельная теорема
Если у нас есть независимо одинаково распределённые случайные величины, то их сумма $S_n = \sum_{k=1}^n X_k$ будет стремиться к нормальному, но не до конца, тогда как
$$
\frac{S_n - nEX_1}{\sqrt{nDX_1}} \rarr N_{0,1}
$$
То есть стремится к нормальному
